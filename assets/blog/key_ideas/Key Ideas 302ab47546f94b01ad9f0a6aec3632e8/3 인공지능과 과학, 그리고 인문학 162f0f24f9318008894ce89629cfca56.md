# 3. 인공지능과 과학, 그리고 인문학

*Acknowledgement: 피드백 주신 물리연구소 오픈톡방의 “하기분미”님께 감사의 말씀 전합니다*

인간만의 특징을 찾아내고 그것에 대한 가치를 느끼는 것은 본능에 가깝다. 인공지능 시대의 대격변을 경험하고 있는 사람이라면 누구나 이러한 욕구를 한번쯤은 느꼈을 것이다. ‘나’는 ‘나’이기 이전에 사람이고, 이 사실은 나의 정체성을 형성하는 가장 중요한 부품이기에, 인간만이 가지는 특성이 무엇인지에 대해서 마지막까지 고민해보지 않으면 안 된다.

급변하는 “기술의 홍수” 아래, 인공지능 연구자가 방향타를 쥐고 향해하기 위해 단순 기술적 지식과 더불어 인간, 그리고 사회에 대한 이해를 적극적으로 추구해야 한다고 필자는 주장한다. 그러나, 인문학이 필요한 사례들을 단순히 열거하면서 주장을 둘 혹은 세네 가지 근거로 합리화하는 기존의 논설문 방식으로는 입체적인 그림을 그리기가 어렵다고 보았다. 따라서, 인간의 본질에 대해 질문하고 사색하는 과정에서 자연스럽게 논의를 사회와 법규에 관한 이야기로 이어보고자 한다. 아울러, 법적 윤리적 체계의 확장 가능성을 논하며 인공지능과 조화를 이루는 미래 사회를 그리고자 한다.

인간의 본질, 즉 인간과 다른 사물을 구별짓는 인간만의 고유한 특징은 무엇인가? 시대에 따라 양상은 다르지만 인간은 언제나 고유한 존재이기를 원했다. 프랑스의 사회학자 피에르 부르디외는 '구별짓기'라는 개념을 통해 사람이 다른 사람과 자기 자신을 구별하기 위해 사회적 위계나 차별성 등을 추구한다고 주장했다. 고대 그리스 철학자 아리스토텔레스는 인간만이 유일하게 이성(logos)을 지닌 존재라고 주장하였다. 기독교에서도 인간은 신의 형상을 따 만들어진 고귀한 존재로 여긴다. 이처럼 인간은 유구한 역사와 다양한 문화에서 스스로를 드높이기 위한 사고의 틀을 만들며 살아왔다.

물론 1500년대 코페르니쿠스의 지동설과 1800년대 다윈의 진화론 등의 과학 이론들은 인간중심적 사고의 정반대편에서 전통적인 종교적 세계관을 뒤흔드는 듯했다. 인간이 사는 지구가 우주의 중심이 아니며, 인류가 수많은 종(種)들 중 어느 하나에 불과하다는 사실은 당대 사람들에게 큰 충격을 주었다. 그러나, 인간은 도구를 자유자재로 활용하거나 문자를 만들어 사용하는 등 여타 동물이나 사물과 비교해볼 때 여전히 특징적이었다. 특히 아리스토텔레스가 주장한 이성의 중요성은 여전히 유효했다. 과학과 기술이 기존 인간중심주의적 패러다임의 일부를 반박했을지언정, 실제로는 문명 발전을 가속화하고 인류의 위상을 드높이는 도구로 적극적으로 활용되었다. 인간중심주의에 대한 새로운 해석은 과학과 기술이 인간의 가치를 평가절하하는 일을 효과적으로 방지했다.

> “약 50년 후면 대략 $10^9$ 비트(약 128MB)의 저장 용량을 갖춘 컴퓨터를 프로그래밍하여 ‘모방 게임(imitation game)’을 매우 능숙하게 수행하도록 만들 수 있을 것이며, 그 결과 평균적인 심문관이 5분간의 질의 후에 올바른 대상을 정확히 식별할 확률이 70퍼센트 이하가 될 것이라고 믿는다. 또한 세기 말이 되면 단어 사용 방식과 일반 지식인들의 인식이 크게 변화하여, ‘기계가 사고한다’고 표현하더라도 더 이상 이의를 제기받지 않을 것이라고 생각한다.”
A. M. TURING, I.—COMPUTING MACHINERY AND INTELLIGENCE, *Mind*, Volume LIX, Issue 236, October 1950, Pages 433–460
> 

오늘날의 컴퓨터는 이성적 사고의 기반이 되는 논리 구조를 추상화하여 물리적으로 연산 가능한 형태로 구현한 것이다. 그러나 컴퓨터가 지닌 단순 계산 능력이 지성을 함의하지는 않으며, 실제로 인간의 지성을 컴퓨터로 유의미하게 모사할 수 있을 때까지는 오랜 기간이 걸렸다. 튜링은 1950년 그의 논문 “계산 기계와 지성”에서 “5분간의 질의 후에 기계와 인간을 정확히 식별할 확률이 70퍼센트를 넘지 않는” 기계가 50년 후인 2000년 경에 등장하리라 예견한 바 있다. 컴퓨터의 창시자가 일찍이 인공지능의 발전을 예측하고 이를 평가하기 위한 시험(튜링 테스트)을 고안했음은 놀라운 사실이나, 전혀 다른 물리적 기반 위에서 동작하는 두 시스템이었기에 한쪽에서 쉬운 작업이 다른 쪽에서 어려운 “모라벡의 역설”은 오랜 기간 지속되었다.

모라벡의 역설 덕분에 다양한 지능의 영역 중 ‘학습’만큼은 인간 고유의 영역으로 남는 듯 했으나, 기계학습의 급속한 발전 덕택에 인공지능은 인간의 지적 노동을 상당 부분 대체할 수 있을만큼 발전하였다. 우리는 최근 전 분야에 걸쳐 각 분야의 전문가들보다 인공지능이 더 우수한 지적 탐구물을 내놓는 사례들을 목도하고 있다. 최근 공개된 OpenAI의 Deep Research (o3) 모델은 대학원 수준 지식과 논리력을 평가하기 위해 고안된 GPQA Diamond에서 87.7%의 정확도를 보여 각 분야 박사급 전문가 집단의 정확도인 81.3%를 능가하였으며, 극단적 수준의 언어 추론 및 수리 사고력을 평가하는 "인류의 마지막 시험" 벤치마크에서는 26% 상당의 정답률을 보였다. 사회가 인공지능을 받아들이기 위해 필요한 인식적 변화는 차치하고서라도, 객관적 지표 측면에서 볼 때 공무원, 개발자, 컨설턴트를 포함한 많은 화이트 칼라 직종이 조만간 기계에 의해 (적어도 기능적으로는) 자동화 가능해질 것으로 보인다. 러다이트 운동 당시에 기계가 그러했듯, 현대 사회에서 인공지능은 많은 이들에게 존재론적 위협으로 다가오고 있다.

이제 우리에게 남아있는 것은 이러한 기계가 실수를 저지를 때 그 실수를 바로잡는 것뿐인 것만 같다. 리산 베인브리지는 그의 논문 자동화의 아이러니(Ironies of Automation)에서 자동화된 사회에서 인간은 자동화가 실패할 경우를 대비해 감시하고 개입하는 역할만을 맡게 되지만, 이러한 역할은 매우 드물게 발생하므로 정작 인간이 실제로 개입해야 할 때 필요한 기술과 경험을 갖추지 못하게 됨을 주장하였다. 칸트의 의무⋅능력 원리(Ought Implies Can)는 의무를 지기 위해서는 반드시 그 의무를 수행할 수 있는 능력이 전제되어야 한다고 가정한다. 이에 따라, 어떤 행위자가 도덕적 책임을 질 수 있기 위해서는 자유 의지를 가짐이 우선되어야만 한다. 자동화가 실패하는 방식은 다양하더라도 결국은 인간이 이 모든 사태의 책임을 져야 한다는 사실은 현재의 법적 테두리 안에서 명백해보인다. 자유의지를 지니고 있지 않다고 여기어지는 현재의 인공지능 "에이전트"의 행위에 대해 인간이 온전한 책임을 질 수 있을까?

물론, 의식과 자유의지 등의 개념을 정량화한 후, 일종의 “책임질 수 있음의 척도”를 만들어 인공지능에게 책임을 물을 수 있다고 주장하거나, 반대로 책임을 물을 수 없음을 주장할 수도 있겠다. 이를테면, 의식의 크기를 계산하고자 Integrated Information Theory 등을 도입하고, 자유 의지를 규명하고자 Orchestrated Objective Reduction 등의 이론을 차용해보는 것이다. 이처럼, 문제 상황을 분석하기 위한 정량화된 척도를 개발하거나, 물리량을 정의하여 이를 수학적으로 분석하고자 하는 행위는 과학자들에게 매우 일상적이다. 오귀스트 콩트가 주장한 고전적 실증주의에 따르면 과학은 “객관적으로 관찰 가능한 것들을 논리 구조를 통해 더 명확하고 엄밀하게 설명하기 위해 존재”하며, 논리적 실증주의로 넘어오면서는 객관적으로 관찰 가능한 사실에 더해, 순수 논리 및 수학으로 참임을 보일 수 있는 명제만이 인지적 의미를 지닌다고 믿었다. 이처럼 실증주의가 지배적이던 19세기와 20세기에는 객관적이거나 관찰 가능하지 않은 대상은 배제시키게 만들 정도로 실증주의는 당대 과학의 핵심에 있는 사상이었다.

물론 실증주의는 이백년도 넘게 된 오래된 관점이고, 현대에 이르러 철학자와 과학철학자 집단 사이에서는 과학적 실재론이 과반 이상의 지지를 받고 있다. 그러나, 과학적 실재론에서도 여전히 과학적 대상은 마음과 전적으로 독립적으로 존재한다고 주장한다. 어느 쪽이 되었든, 진실에 다가가기 위해 우리가 스스로 쳐놓은 울타리들이 개개인의 가치 판단이 과학에 영향을 미치지 못하도록 방어막을 형성하고 있음에는 의문의 여지가 없다. 이에 따라, 지능이나 자의식, 자유의지, 사회적 책임 등의 문제를 접근할 때에는 과학만으로 돌파할 수 없는 상당한 장벽을 맞이하게 된다. 요약하자면, 가치 판단이 요구되는 순간부터 과학은 많은 힘을 잃어버린다.

현재의 인공지능 학계 역시 여타 이공계역 학문과 다르지 않게 수리과학적 분석과 실험적 증거 둘 중 적어도 하나의 구성 요소는 논문이 주요 컨퍼런스지에 게재되기 위해 사실상 필수적이다. 그렇지 않다면 벡터나 파라미터, 데이터와 문자열 따위의, 단순히 사람의 생각에 비유적으로 연관시키기 위해 기술적으로 엄밀한 개념들을 차용할 이유가 있을까? 그렇지만, 심적 상태를 정확히 묘사하기 위해서는 과학적으로 엄밀한 대상만이 아닌 주관적 경험이나 가치 판단을 중심으로 하는 인문학적 개념 또한 진지한 연구 대상으로 고려되어야 한다. 인간과 인공지능 같은 지적 대상체에 대해, 과학적이고 객관적인 접근이 모든 것을 설명할 수 있을지는 미지수이다. 또한, 과학적이고 객관적으로 접근하고자 연구자가 아무리 노력하더라도, 결국 연구를 수행하는 주체는 사람이며, 연구자의 이론적 가정과 편견이 관찰에 영향을 미칠 수 있음을 우리는 인정해야만 한다.

실증주의를 비판 및 수정하는 포스트 실증주의에 따르면 연구자 스스로의 편향은 절대적 진리에 다가가기 위해 해결해야 할 문제로 인식되며, 연구자는 항상 자신의 편향을 인식하고 교정하고자 노력해야 한다. 그러나, 연구자의 편향과 가치관이 반드시 문제적인가? 우리는 그동안 학문을 연구함에 있어 객관성에 대해 오래토록 집착해왔다. 하지만, 그 집착을 완화함으로써 새로운 개념을 제안하고 연구의 지평을 확장할 수 있다면 어떨까?

![IMG_1711.jpeg](3%20%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EA%B3%BC%20%EA%B3%BC%ED%95%99,%20%EA%B7%B8%EB%A6%AC%EA%B3%A0%20%EC%9D%B8%EB%AC%B8%ED%95%99%20162f0f24f9318008894ce89629cfca56/IMG_1711.jpeg)

한 예시로, 인공지능 로봇이 사회와 상호작용하는 방식과 대중이 로봇을 받아들이는 심리적인 과정을 탐구하는 연구자가 있다고 가정해보자. 현 사회는 ChatGPT 등 인공지능 에이전트와 상호작용할 때 도덕성을 갖추어 대할 것을 요구하지 않는다. 그렇지만 로봇과 사람이 정말로 구분되지 않고 외형마저 유사해지는 미래 사회에는 로봇을 인간처럼 대우해야 한다고 믿는 사람들도 발생하지 않을까? 위의 스크린샷 속 ChatGPT의 앱스토어 리뷰처럼, 당신이 가지고 있는 믿음과 무관하게 이미 일반 대중은 인공지능에게 설득 당하고, 종종 위로 받으며, 또 감정적으로 교류하고 있다. 미래 사회에 우리와 일상을 함께할 ”비인간“을 설계함에 있어서, 벤치마크의 정량적인 지표를 최대화하는 공학적 접근이 역사적으로 전례 없는 인간과 기계의 복잡미묘함 상호작용을 제대로 모델링할 수 있으리라 생각하는가?

이제 우리는 개개인의 주관과 가치 평가를 인공지능 연구의 핵심으로 끌여들여야만 한다. 집에서 키우는 아이가 흡사 사람같은 인공지능 가사 도우미 로봇과 정이 들어버린 상황을 생각할 때, 로봇을 폐기하기로 결정하는 행위가 비윤리적이라 주장할 수 있는 “객관적인” 근거는 마땅히 없다. 그러나, 아이의 주관적 입장에서는 애착 인형도, 강아지도, 자신을 도와주는 가사 도우미 로봇도 전부 나와 ‘유사’하기 때문에 보호의 대상이다. 나와 타인이 동격이라는 믿음의 근간에는 “상호 유사성”이 있다. 만일 서로 비슷함에도 타인이 나와 동등한 관계에 있다고 믿지 않는다면, 그리고 타인이 또 다른 타인에게 해를 가하던 말건 ‘나’에게 해가 없다면, 사실 ‘나’의 입장에서 타인에게 행해지는 잘못을 제재할 이유는 전혀 없다. 그러나, 타인과 나의 상호 유사성은 타인에게 가해지는 해가 나에게도 위협으로 인지되게 만들며, 또 나와 동등한 관계로 인식하게 만든다.

법은 언제까지나 사람 대 사람 관계에서 발생할 수 있는 부조리를 예방할 뿐 기계를 보호하지 않는다. 대다수의 인공지능 학자들은 기계가 마음을 가진다고 여기지 않으며, 노엄 촘스키처럼 LLM이 통계학적 앵무새에 불과하다고 보는 입장도 상당히 일반적이다. 물리적인 관점에서 볼 때 인간과 기계는 기반이 되는 물질이 다르고 작동 메커니즘도 다르다. 그러나, 유사성을 판단하는 주체가 개개인임을 고려할 때, 또한 인식은 주관에 따라 변화함을 고려할 때, 위의 스크린샷에 담긴 복잡한 사회 현상을 설명하기 위해 단순 물리적인 차이를 논하는 것은 역부족이다.

이제까지 살펴본 바와 같이, 인공지능은 단순 계산 기계를 넘어 학습·추론·창의의 영역까지 침투하고 있으며, 그로 인해 인간 고유의 특성—이성, 의식, 책임, 그리고 사회적 유대—에 대한 재검토가 불가피해졌다. 실증주의와 논리적 실증주의가 객관적 사실과 순수 논리에만 집중해 왔다면, 포스트 실증주의는 연구자의 주관과 가치판단까지 문제 삼는다. 그러나 과학은 언제까지나 도구에 불과할 뿐, 이제는 ‘어떤 질문을 던질 것인가’, 그리고 ‘어떤 사회를 그릴 것인가’라는 의문을 연구의 핵심으로 끌어들여야 한다는 입장이다. 이는 인공지능 연구에도 적용되어야 하는 패러다임 전환을 의미한다. 즉, ‘어떤 의미와 맥락에서’ 인공지능의 존재를 이해하고 또 어디까지 책임질 것인지가 더 중요해진 것이다.

미래 사회에서 인공지능 에이전트가 생산·서비스·돌봄·창작 등 광범위한 역할을 맡게 되면, “기계는 언제나 기계일 뿐”이라는 전통적 분류 기준은 설득력을 잃는다. 대신 우리는 ‘상호 유사성’과 ‘정서적 유대’ 등 새로운 잣대를 고민해야 할 수 있다. 로봇에 대한 애착과 보호의 정당성을 다룰 법·윤리 체계를 설계하려면, 기존의 ‘인간 전용’ 법적 지위에 대한 근본적 확장이 필요하다. 가령, 돌봄 로봇의 과오에 대해 누가, 어떻게 책임지는가를 명시하고, 인공지능 자체가 일정 수준의 권리·의무를 지닐 수 있는 가능성을 열어놓아야 할 것이다.

결국, 인공지능 시대의 연구자와 정책입안자는 기술적 완성도만큼이나 ‘인간다움’의 의미를 함께 성찰해야 한다. 과학이 객관적 진실을 탐구하는 동안에도, 주관적 경험과 사회적 맥락을 이해하려는 노력이 병행되어야 한다. 이를 위해 인문학·사회과학·법학이 공학 연구실에, 그리고 정책 논의 테이블에 동석해야 한다. 그렇게만 할 때 비로소, 우리는 인공지능과 공존하면서도 인간의 존엄과 책임을 온전히 지킬 수 있는 사회를 설계할 수 있을 것이다.