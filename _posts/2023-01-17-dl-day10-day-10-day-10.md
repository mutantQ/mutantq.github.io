---
layout: post
title: "Day 10: Day 10 다변수로의 확장과 인공신경망"
date: 2023-01-17 10:00:00
description: 딥러닝의 기초 - Day 10
tags: deep-learning tutorial korean education series
categories: education
---


### 다변수로의 확장

지금까지 선형대수학과 코딩의 기초를 다지고, 일변수 함수에 대해서 경사하강법을 이용하여 국소 최소점을 찾는 방법을 다뤘다. 하지만 이는 최적화하고자 하는 변수의 개수가 단 한 개, 즉 $n=1$인 경우에 불과하며, 실제로 인공지능에서 사용하는 경사하강법의 경우 $n$의 값이 매우 크다. 따라서 우리는 경사하강법을  $n$이 임의의 자연수인 경우로 일반화하는 과정을 거쳐야 한다. $n$이 백만, 천만인 경우도 물론 다룰 것이지만, 너무 겁먹지는 말자. 실제로는 $n=2$인 경우만 이해하면 큰 $n$에 대하여 일반화하는 것은 어렵지 않다.

그래디언트는 미분을 다변수로 확장한 개념이다. 선형대수학을 배웠으니, 이제 인공신경망과 그래디언트의 개념을 동영상을 통해 함께 살펴볼 것이다. 그 이전에, 선행 지식인 벡터와 다변수함수의 개념을 딥러닝의 맥락에서 간략히 소개하겠다.

### 모든 정보는 벡터다

우리가 일상 생활에서 접하는 거의 대부분의 정보는 벡터로 표현 가능하다. 벡터는 쉽게 말하면 수들의 순서쌍이다. 대표적인 예시로, 이미지는 위치별 밝기 정보를 나타내는 벡터로 표현할 수 있다. 이미지는 여러 픽셀로 구성되어 있으며, 각각의 픽셀에 빨간색, 초록색, 파란색이 얼마나 섞여 있는지를 표현하기 위해 픽셀마다 $(r, g, b)$의 값을 특정한다. 예를 들어, 아래와 같이 말이다:

$$
\textrm{(image with 5 pixels)}=(r_1,g_1,b_1,r_2,g_2,b_2,r_3,g_3,b_3,r_4,g_4,b_4,r_5,g_5, b_5)\\=(0,0,1,1,1,1,1,0,0,0,0,0,1,1,0)
$$

![Untitled](/assets/img/blog/deep-learning/untitled.png)

이와 같은 원리로, 더 많은 픽셀을 사용하면 아래와 같은 이미지를 얻는다. 픽셀의 개수가 많아질수록 이미지를 더욱 상세하게 표현할 수 있게 된다.

![Untitled](/assets/img/blog/deep-learning/untitled_1.png)

비슷한 원리로, 소리·텍스트·문서·프로그램 등의 정보 역시 모두 벡터로 표현할 수 있으며, 적절한 실험 장비 혹은 센서가 주어진다면 미각·촉각·온도 등의 정보도 모두 표현할 수 있다고 말할 수 있다.

### 함수와 다변수 벡터함수

중학교, 고등학교 수준에서 배우는 ‘함수’는 대개 숫자 하나를 입력으로 받아 다른 숫자 하나를 내놓는 형태이다.

![Untitled](/assets/img/blog/deep-learning/untitled_2.png)

대학교 수준 이상으로 넘어가면 벡터를 받아 벡터를 내놓는 함수에 대해서도 논하게 된다. 이를 다변수 벡터함수multivariate vector function라고 부른다.

![Untitled](/assets/img/blog/deep-learning/untitled_3.png)

인공신경망도 결국은 벡터가 들어가서 벡터가 나오는 함수에 불과하다. 다만 차이가 있다면, 인공신경망 내에 “파라미터”들이 있어서 파라미터를 바꾸면 함수의 형태가 바뀐다. 아래 영상을 보면서 인공신경망이 무엇인지 감을 잡아보자.

### CH1 | But what is a neural network?

[https://www.youtube.com/watch?v=aircAruvnKk](https://www.youtube.com/watch?v=aircAruvnKk)

### 문제 1.1

(a) 동영상에서 언급한 뉴런의 단순한 정의는 무엇인가?

(b) 신경망에서 행렬곱의 역할을 설명하시오.

(c) 함수라는 용어를 사용하여 동영상에서 언급한 뉴런의 완전한 정의를 설명하시오.

(d) 각 함수의 공식을 제시하고 그래프를 그리시오: $y=\sigma(x), \; y=\textrm{ReLU}(x).$ 어느 함수가 (컴퓨터에서) 더 간단하게 계산되는가?

(e) 레이어란 무엇인가? 뉴런의 정의를 바탕으로 레이어가 무엇인지 설명하시오.

### 문제 1.2

다음 벡터 표현식을 개별 원소에 대한 표현으로 바꿔보시오.

$$
\mathbf{a}^{(1)}=\sigma(W\mathbf{a}^{(0)}+\mathbf{b})
$$