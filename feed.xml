<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://codingjang.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://codingjang.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-12-05T13:02:36+00:00</updated><id>https://codingjang.github.io/feed.xml</id><title type="html">blank</title><subtitle>Yejun Jang is an AI researcher specializing in reinforcement learning and deep learning at Seoul National University. </subtitle><entry xml:lang="ko"><title type="html">공동창업자 (하드웨어 엔지니어) — mutual</title><link href="https://codingjang.github.io/blog/2025/mutual-cofounder-hardware-kr/" rel="alternate" type="text/html" title="공동창업자 (하드웨어 엔지니어) — mutual"/><published>2025-12-05T03:00:00+00:00</published><updated>2025-12-05T03:00:00+00:00</updated><id>https://codingjang.github.io/blog/2025/mutual-cofounder-hardware-kr</id><content type="html" xml:base="https://codingjang.github.io/blog/2025/mutual-cofounder-hardware-kr/"><![CDATA[<p><img src="/assets/img/mutual-logo.jpg" alt="mutual 로고"/></p> <p><strong>“이 영상, 진짜야?” 라는 질문에 답할 수 있는 기술을 만듭니다.</strong></p> <p>AI가 만든 영상과 진짜 영상, 이제 눈으로는 구분이 안 됩니다. 소프트웨어로 가려내는 건 한계가 있고요. mutual은 다르게 접근합니다. 카메라가 찍는 순간, 하드웨어 안에서 바로 서명합니다. 소프트웨어가 손댈 틈이 없어요. 기술적인 구조가 궁금하다면 화이트페이퍼(PDF) <a href="/assets/pdf/SRA-2025-10-05.pdf">Signing Right Away</a>를 읽어보는 것도 좋습니다.</p> <h2 id="누가-투자했나요">누가 투자했나요?</h2> <p><strong>우경식 (Kay Kyungsik Woo)</strong></p> <p>블록체인 기반 모빌리티 플랫폼 <a href="https://mvlchain.io">MVL Foundation</a>의 창업자이자 CEO입니다. MVL이 만든 TADA는 200만 유저, 20만 드라이버가 쓰는 서비스예요. 400억 이상 투자 유치, 글로벌 250명 규모, 2022년 흑자 전환. 실제로 스케일하는 서비스를 만들어본 분입니다.</p> <h2 id="무슨-일을-하게-되나요">무슨 일을 하게 되나요?</h2> <ul> <li>FPGA로 암호화 가속기 설계 (AES-GCM/CCM 같은 것들)</li> <li>이미지 센서에서 TEE까지, 안전한 파이프라인 구축</li> <li>SRA 아키텍처의 레퍼런스 구현</li> </ul> <h2 id="이런-분을-찾습니다">이런 분을 찾습니다</h2> <ul> <li>Verilog나 HDL 다뤄본 경험</li> <li>2025년 겨울 ~ 2026년 봄 사이에 풀타임 가능</li> <li>영어 커뮤니케이션에 문제 없는 분 (해외 출장, 글로벌 파트너 미팅 있어요)</li> </ul> <h2 id="있으면-좋아요">있으면 좋아요</h2> <ul> <li>암호화 가속기 설계해본 적 있다면 최고</li> <li>MIPI CSI-2나 카메라 인터페이스 알면 플러스</li> </ul> <h2 id="드릴-수-있는-것">드릴 수 있는 것</h2> <ul> <li><strong>지분 기본 10%, 최대 20%</strong> — 공동창업자 레벨입니다</li> <li><strong>해외 출장</strong> — 컨퍼런스, 파트너 미팅 등</li> <li>어렵지만 의미 있는 문제</li> </ul> <hr/> <p><strong>궁금하신 게 있다면</strong> → <a href="mailto:jangyejun@snu.ac.kr">jangyejun@snu.ac.kr</a></p>]]></content><author><name></name></author><category term="hiring"/><category term="startup"/><category term="hiring"/><category term="cofounder"/><category term="hardware"/><category term="fpga"/><category term="verilog"/><summary type="html"><![CDATA[AI 시대의 신뢰 인프라를 구축합니다. 기술 공동창업자를 찾습니다.]]></summary></entry><entry xml:lang="en"><title type="html">Co-Founder (Hardware Engineer) — mutual</title><link href="https://codingjang.github.io/blog/2025/mutual-cofounder-hardware/" rel="alternate" type="text/html" title="Co-Founder (Hardware Engineer) — mutual"/><published>2025-12-05T03:00:00+00:00</published><updated>2025-12-05T03:00:00+00:00</updated><id>https://codingjang.github.io/blog/2025/mutual-cofounder-hardware</id><content type="html" xml:base="https://codingjang.github.io/blog/2025/mutual-cofounder-hardware/"><![CDATA[<p><img src="/assets/img/mutual-logo.jpg" alt="mutual logo"/></p> <p><strong>We make digital content provably authentic at the hardware level.</strong></p> <p>AI-generated media is indistinguishable from reality. Software detection doesn’t work. At mutual, we’re building cryptographic signing directly into camera hardware—so content is authenticated the moment it’s captured, before it ever touches software.</p> <p>If you’d like to understand the architecture in more detail, you can read our whitepaper (PDF): <a href="/assets/pdf/SRA-2025-10-05.pdf">Signing Right Away</a>.</p> <h2 id="backed-by">Backed By</h2> <p><strong>Kay Kyungsik Woo</strong> — Founder &amp; CEO of <a href="https://mvlchain.io">MVL Foundation</a>, the company behind TADA, a blockchain-based ride-hailing platform operating across Southeast Asia. Kay brings deep experience in building trust infrastructure for real-world applications.</p> <h2 id="what-youll-build">What You’ll Build</h2> <ul> <li>Cryptographic accelerators on FPGA (AES-GCM/CCM, authenticated encryption)</li> <li>Secure pipelines between image sensors and trusted execution environments</li> <li>Reference implementation for our SRA (Signing Right Away) architecture</li> </ul> <h2 id="requirements">Requirements</h2> <ul> <li>Verilog or HDL experience</li> <li>Can go full-time between Winter 2025 – Spring 2026</li> </ul> <h2 id="nice-to-have">Nice to Have</h2> <ul> <li>Crypto accelerator design experience</li> <li>MIPI CSI-2 / camera interface knowledge</li> </ul> <h2 id="what-we-offer">What We Offer</h2> <ul> <li><strong>Default 10%, up to 20% equity</strong> — true co-founder stake</li> <li><strong>Hybrid-remote</strong> — work remotely, but able to be in Seoul periodically for in-person collaboration</li> <li>Hard technical problem with real-world impact</li> </ul> <hr/> <p><strong>Interested?</strong> → <a href="mailto:jangyejun@snu.ac.kr">jangyejun@snu.ac.kr</a></p>]]></content><author><name></name></author><category term="hiring"/><category term="startup"/><category term="hiring"/><category term="cofounder"/><category term="hardware"/><category term="fpga"/><category term="verilog"/><summary type="html"><![CDATA[We're building the trust layer for the post-AI media era. Looking for a technical co-founder.]]></summary></entry><entry xml:lang="ko"><title type="html">mutual을 소개합니다</title><link href="https://codingjang.github.io/blog/2025/introducing-mutual-kr/" rel="alternate" type="text/html" title="mutual을 소개합니다"/><published>2025-12-05T01:00:00+00:00</published><updated>2025-12-05T01:00:00+00:00</updated><id>https://codingjang.github.io/blog/2025/introducing-mutual-kr</id><content type="html" xml:base="https://codingjang.github.io/blog/2025/introducing-mutual-kr/"><![CDATA[<p><img src="/assets/img/mutual-logo.jpg" alt="mutual 로고"/></p> <p>스마트폰 카메라 셔터를 누르는 순간부터 사진이 갤러리에 뜨기까지, 안에서는 무슨 일이 일어날까.</p> <p>나는 요즘 "카메라와 마더보드 사이의 보안"을 보고 있다. 이 한 줄을 이야기하면 사람들은 보통 카메라 해킹, 도촬, 랜섬웨어 같은 것을 떠올린다. 하지만 내가 정말로 신경 쓰는 건 조금 다르다.</p> <p>질문을 하나 던져보자.</p> <blockquote> <p>"앞으로 5년 뒤, 우리가 보는 영상과 사진 중 얼마나 많은 비율이 생성형 AI가 만든 것일까?"</p> </blockquote> <p>정답을 아는 사람은 없지만, 한 가지는 분명하다. 어떤 이미지가 진짜인지 아닌지 <strong>통계적으로</strong> 구분하는 것은 생성형 인공지능이 충분히 발전하면 불가능해질 것이다. “인공지능 모델로 생성된” 이미지의 분포가 “실제 카메라로 찍힌 이미지”의 분포로 수렴할 것이기 때문이다.</p> <p>이 문제를 어떻게 풀 수 있을까. 최근 몇 년 사이, 미국과 유럽의 빅테크 기업들이 하나의 방향을 잡았다. Adobe가 주도하고 Google, Sony, OpenAI 등이 참여하는 연합이 있다. <strong>C2PA(Coalition for Content Provenance and Authenticity)</strong>라는 이름의 기술 표준이다.</p> <p>C2PA의 목표는 단순하다. 콘텐츠가 만들어지는 전 과정을 기록하고, 그 기록을 암호학적으로 보호한 뒤, 나중에 누가 언제든 검증할 수 있게 하자는 것이다. 말하자면 디지털 콘텐츠의 "제작 이력서"를 남기는 일이다.</p> <p>여기서 자연스럽게 다음 질문이 나온다.</p> <blockquote> <p>"그렇다면, 그 기록의 가장 처음은 어디여야 할까?"</p> </blockquote> <p>문서 편집기? 사진 편집 프로그램? 클라우드 서버?</p> <p>우리는 그 답이 <strong>센서</strong>, 즉 카메라가 세상을 처음 받아들이는 그 지점에 있다고 믿는다.</p> <p>한 번 센서를 떠난 신호는, 이론상 얼마든지 복제되고 조작될 수 있다. 반대로 말하면, <strong>센서에서 카메라 프로세서로 넘어가는 그 순간</strong>에 신호를 잠그고 서명할 수 있다면, 이후의 모든 단계는 그 서명을 기준으로 검증할 수 있다.</p> <p>mutual은 바로 그 지점을 다루는 회사다.</p> <h2 id="우리가-보는-문제">우리가 보는 문제</h2> <p>레몬 마켓(lemon market)은 좋은 상품과 나쁜 상품이 섞여 있는 시장을 뜻한다. 겉으로는 품질을 알기 어렵기 때문에, 구매자는 항상 “최악의 경우”를 염두에 두고 낮은 가치를 부여하게 되고, 그 결과로 품질이 좋은 상품(예: 진짜 영상)의 가치도 함께 떨어지게 된다.</p> <p>오늘의 인터넷은 일종의 레몬 마켓에 가깝다. 좋은 정보와 나쁜 정보, 진짜 영상과 가짜 영상이 섞여 있고, 둘의 차이를 구분할 수 없다면 소비자들은 모든 컨텐츠를 불신하게 된다. 정보 비대칭이 심해질수록 신뢰는 떨어지고, 결국 모두가 손해를 보는 구조다.</p> <p>지금까지의 많은 시도는 "사후 탐지"에 초점을 맞췄다. 이미 생성된 콘텐츠를 보고 진짜/가짜를 분류하는 방식이다. 하지만 생성형 모델이 고도화될수록, 화면에 드러난 결과만 보고 진위를 가리는 일은 점점 더 어려워진다.</p> <p>그래서 우리는 질문을 바꿔보기로 했다.</p> <blockquote> <p>"이미지를 만들어 낸 <strong>출처</strong>를 증명할 수 있다면 어떨까?"</p> </blockquote> <h2 id="mutual의-접근-signing-right-away">mutual의 접근: Signing Right Away</h2> <p>mutual의 핵심 기술은 <strong>SRA(Signing Right Away)</strong>라는 아키텍처다. 이름 그대로, <strong>만들어지는 그 순간에 바로 서명하는 것</strong>이 목표다.</p> <p>생각하는 흐름은 단순하다.</p> <ol> <li>이미지 센서에서 나오는 신호가 카메라 프로세서로 들어간다.</li> <li>이 구간을 하드웨어 수준에서 암호화하고, 위변조를 막는다.</li> <li>보안 영역(TEE) 안에서만 복호화하고, 거기서 메타데이터와 함께 서명한다.</li> <li>최종적으로 C2PA 표준을 따르는 콘텐츠 자격 증명을 붙여 파일을 만든다.</li> </ol> <p>이렇게 하면 나중에 누가 이미지를 열어보더라도, "이 파일이 실제 센서에서 시작된 것인지", "중간에 조작이 있었는지"를 검증할 수 있다. 중요한 건, 이 신뢰의 뿌리가 소프트웨어가 아니라 <strong>하드웨어</strong>에 놓인다는 점이다.</p> <p>보다 기술적인 구조와 세부 내용은 화이트페이퍼(PDF) <a href="/assets/pdf/SRA-2025-10-05.pdf">Signing Right Away</a>에 정리해 두었다.</p> <h2 id="어떻게-여기까지-왔는가">어떻게 여기까지 왔는가</h2> <p>2024년 봄, SRA 아이디어를 논문 형식으로 정리했다. 군 복무로 프로젝트는 멈췄고, 전역 후 친구들과 다시 모여 프로토타입을 만들기 시작했다. 공식 문서도 없는 상태에서 MIPI CSI-2 카메라 인터페이스를 직접 분석해 보안 전송을 얹어 보려 했다.</p> <p>결과는 실패에 가까웠다. 쓰던 FPGA는 메모리가 턱없이 부족했고, 프로토콜을 추측에 기대어 구현하다 보니 영상이 간헐적으로 깨졌다. 무엇이 문제인지, 어떤 자원이 필요한지는 분명해졌지만, 우리가 가진 장비와 시간으로는 더 이상 나아가기 어려웠다.</p> <p>그때 MVL Foundation의 우경식 대표를 만났다. MVL은 동남아시아에서 TADA라는 모빌리티 서비스를 운영한다. 200만 명이 쓰는 서비스이고, 수십만 명의 드라이버가 매일 그 위에서 일한다. 블록체인 기반 모빌리티라는 낯선 영역에서 실제로 사업을 키워 온 팀이다.</p> <p>우 대표 앞에서 SRA를 설명했다. 왜 센서가 중요하다고 생각하는지, 왜 지금 이 시점에 이 기술이 필요하다고 보는지, 왜 하드웨어를 건드려야 하는지.</p> <p>이야기 끝에, mutual은 첫 엔젤 투자를 받았다.</p> <h2 id="mutual이라는-이름">mutual이라는 이름</h2> <p>회사 이름을 정할 때 가장 먼저 떠올렸던 단어가 "신뢰"였다. 하지만 우리가 풀고 싶은 문제는 한쪽이 다른 한쪽을 일방적으로 믿는 구조가 아니다. 서로가 서로를 믿을 수 있는 조건을 기술로 만드는 일이다.</p> <p>그래서 <strong>mutual</strong>이라는 이름을 골랐다.</p> <blockquote> <p>정보 비대칭이 존재하는 곳에 기술적 신뢰를 제공해, 상호 신뢰를 회복하는 것.</p> </blockquote> <p>이 문장을 조금씩 다듬어가며, 우리가 만들고 싶은 회사의 방향을 잡아 가고 있다.</p> <h2 id="앞으로">앞으로</h2> <p>Qualcomm Snapdragon 8 Gen 3는 이미 C2PA를 하드웨어 레벨에서 지원하기 시작했다. Truepic 같은 회사는 Qualcomm의 TEE를 활용해 비슷한 아이디어를 시장에 내놓고 있다. 이 방향이 틀리지 않았다는 신호다.</p> <p>mutual은 특정 칩이나 특정 회사에 종속되지 않는 <strong>레퍼런스 아키텍처</strong>를 만들고자 한다. 어떤 SoC든, 필요한 보안 블록만 제공한다면 그 위에 올릴 수 있는 형태의 설계다. 비즈니스 모델은 ARM처럼 IP를 라이선싱하는 구조를 염두에 두고 있다.</p> <p>지금은 연구와 프로토타입, 기술 표준 문서와 하드웨어 스펙 파헤치기가 하루 대부분을 채운다. 그리고 곧, 이 길을 함께 걸어갈 하드웨어 엔지니어 공동창업자를 맞이하게 되기를 기대하고 있다.</p> <p>관심이 생겼다면, <a href="/blog/2025/mutual-cofounder-hardware-kr/">채용 공고</a>를 읽어보고 꼭 지원해주었으면 한다. 간단히 이메일 남겨서 커피챗 가지는 것도 좋다 :) 아래 연락처로 지원 바란다.</p> <hr/> <p><strong>연락처</strong>: <a href="mailto:jangyejun@snu.ac.kr">jangyejun@snu.ac.kr</a></p>]]></content><author><name></name></author><category term="announcement"/><category term="startup"/><category term="mutual"/><category term="content-authenticity"/><category term="hardware-security"/><summary type="html"><![CDATA[AI 시대의 신뢰 인프라를 만듭니다]]></summary></entry><entry xml:lang="en"><title type="html">Introducing mutual</title><link href="https://codingjang.github.io/blog/2025/introducing-mutual/" rel="alternate" type="text/html" title="Introducing mutual"/><published>2025-12-05T01:00:00+00:00</published><updated>2025-12-05T01:00:00+00:00</updated><id>https://codingjang.github.io/blog/2025/introducing-mutual</id><content type="html" xml:base="https://codingjang.github.io/blog/2025/introducing-mutual/"><![CDATA[<p><img src="/assets/img/mutual-logo.jpg" alt="mutual logo"/></p> <p>Smartphone cameras capture billions of photos and videos every day. Between the moment light hits the sensor and the moment a file is stored or uploaded, that data passes through a long chain of hardware and software. mutual focuses on the earliest part of this pipeline, where physical signals are first converted into digital data.</p> <p>Over the coming years, a growing share of the media we consume will be generated or heavily modified by AI systems. At that scale, <strong>human perception alone is no longer enough to reliably distinguish authentic content from fabricated content.</strong></p> <p>mutual exists to answer a practical question: how do we build infrastructure that makes it possible to trust what we see again?</p> <h3 id="following-the-breadcrumbs">Following the breadcrumbs</h3> <p>Over the last few years, a group of companies in the US and Europe has converged on a particular answer. Adobe, together with Google, Sony, OpenAI and others, is leading a technical coalition called <strong>C2PA (Coalition for Content Provenance and Authenticity)</strong>.</p> <p>The idea behind C2PA is simple to state and hard to implement: record the entire lifecycle of a piece of content, protect that record cryptographically, and make it transparently verifiable to anyone who consumes it later. In other words, give every piece of media a <strong>provenance trail</strong>.</p> <p>If you follow that logic, a natural question appears:</p> <blockquote> <p>If we want a trustworthy record of how content was created, <strong>where should that record start?</strong></p> </blockquote> <p>In a photo editor? In a video export step? On a cloud server?</p> <p>Our answer is: it should start at the <strong>sensor</strong>—at the point where the physical world first becomes digital.</p> <p>Once a signal has left the sensor, it can, in principle, be copied and modified arbitrarily. The inverse is also true: if we can <strong>lock down and sign the signal at the moment it leaves the sensor and enters the camera pipeline</strong>, every later step can be checked against that original commitment.</p> <p>mutual is a company built around that belief.</p> <h2 id="the-problem-we-see">The problem we see</h2> <p>The internet today behaves like a kind of lemon market. High-quality and low-quality information, real and fake media, all sit side by side. As the information asymmetry grows, trust erodes, and everyone ends up paying for it.</p> <p>Most current efforts attack the problem at the end of the pipeline: they try to classify already-generated content as real or fake. As generative models improve, this becomes a losing game. If you only ever see the final pixels, the detector is always chasing the generator.</p> <p>So we decided to change the question:</p> <blockquote> <p>What if, instead of trying to detect fakes, we could <strong>prove the origin</strong> of genuine content?</p> </blockquote> <h2 id="mutuals-approach-signing-right-away">mutual’s approach: Signing Right Away</h2> <p>Our core architecture is called <strong>SRA (Signing Right Away)</strong>. As the name suggests, the goal is to <strong>sign content at the moment it is created</strong>.</p> <p>Conceptually, the flow is straightforward:</p> <ol> <li>A signal comes off the image sensor and enters the camera pipeline.</li> <li>That path is protected at the hardware level using authenticated encryption (AES-GCM/CCM).</li> <li>Only inside a secure enclave (TEE) is the data decrypted and combined with metadata for signing.</li> <li>The final file is produced with C2PA-compliant content credentials attached.</li> </ol> <p>This way, when someone opens an image later, they can ask: "Did this really originate from a physical sensor? Was it tampered with along the way?"—and get a cryptographically grounded answer. The root of trust sits in <strong>hardware</strong>, not just in software that can be bypassed.</p> <p>For a deeper dive into the architecture, you can read the whitepaper (PDF): <a href="/assets/pdf/SRA-2025-10-05.pdf">Signing Right Away</a>.</p> <h2 id="how-we-got-here">How we got here</h2> <p>In spring 2024, I wrote up the first version of SRA as a kind of whitepaper. Then I left for mandatory military service. When I came back, I gathered a few friends, and we tried to turn the idea into a prototype.</p> <p>We aimed high: without official documentation, we tried to reverse-engineer the MIPI CSI-2 camera interface and bolt a secure transport layer on top. It mostly failed. Our FPGA board didn’t have enough memory. Our best-effort understanding of the protocol led to streams that would randomly break. We learned exactly what was wrong and what we needed—but we didn’t have the resources to get there.</p> <p>Around that time, I met <strong>Kay Kyungsik Woo</strong>, founder and CEO of MVL Foundation. MVL runs TADA, a mobility service used by 2 million riders and hundreds of thousands of drivers in Southeast Asia. It’s a team that has actually built and scaled a blockchain-based mobility ecosystem.</p> <p>I walked him through SRA: why the sensor matters, why the timing is right, why this has to live in hardware.</p> <p>At the end of that conversation, mutual got its first angel investment.</p> <h2 id="the-name">The name</h2> <p>When I started thinking about what kind of company I wanted to build, one word kept coming back: trust. But the kind of trust we care about isn’t one-sided. It’s not "just trust us"; it’s creating the <strong>conditions</strong> under which two sides can rationally trust each other.</p> <p>That’s what "mutual" is about.</p> <blockquote> <p>Our mission is to provide technical trust wherever information asymmetry exists, so that mutual trust can be restored.</p> </blockquote> <p>We are still refining that sentence, but it captures the direction of the company.</p> <h2 id="looking-ahead">Looking ahead</h2> <p>Qualcomm’s Snapdragon 8 Gen 3 already supports C2PA at the hardware level. Companies like Truepic are shipping systems built on top of secure camera pipelines. To us, these are strong signals that the ecosystem is moving in the right direction.</p> <p>mutual’s goal is to build a <strong>reference architecture</strong> that is not tied to any single chip or vendor. If a System-on-Chip exposes the right security primitives, our design should be able to run on top of it. On the business side, we are thinking in terms of an ARM-like IP licensing model.</p> <p>For now, we’re a small team based in Seoul. Our days are filled with reading specs, building prototypes, and translating standards into running code. We’re looking forward to adding a a hardware engineer co-founder to the team.</p> <p>If any of this resonates with you, you might enjoy reading the <a href="/blog/2025/mutual-cofounder-hardware/">co-founder role description</a>.</p> <hr/> <p><strong>Contact</strong>: <a href="mailto:jangyejun@snu.ac.kr">jangyejun@snu.ac.kr</a></p>]]></content><author><name></name></author><category term="announcement"/><category term="startup"/><category term="mutual"/><category term="content-authenticity"/><category term="hardware-security"/><summary type="html"><![CDATA[Building trust infrastructure for the post-AI era]]></summary></entry><entry><title type="html">큐비트의 이해</title><link href="https://codingjang.github.io/blog/2025/understanding-qubits/" rel="alternate" type="text/html" title="큐비트의 이해"/><published>2025-10-17T10:00:00+00:00</published><updated>2025-10-17T10:00:00+00:00</updated><id>https://codingjang.github.io/blog/2025/understanding-qubits</id><content type="html" xml:base="https://codingjang.github.io/blog/2025/understanding-qubits/"><![CDATA[<p><em>본 글은 이공계 잡담 및 조언방(카카오톡 오픈채팅)에서 시작된 1일 1글 프로젝트인 <a href="https://publish.obsidian.md/fomakase/">포공방 오마카세</a>의 일환으로 작성된 글입니다.</em></p> <h2 id="양자컴퓨터를-이해하고-싶다면-큐비트부터-이해하자">양자컴퓨터를 이해하고 싶다면 큐비트부터 이해하자</h2> <p>양자컴퓨터는 <strong>양자물리학적 현상을 활용하여 정보를 처리하는 장치</strong>이다. 리처드 파인만이 말했던 것처럼, 양자물리학을 제대로 이해한 사람은 “이 세상에 아무도 없다”. 양자역학이 그토록 악명 높게 어려운데, 양자컴퓨터가 이해하기 쉽다고 말하면 그건 거짓말이다. 그렇지만 그 개념이 우리가 익히 아는 컴퓨터, 즉 “고전” 컴퓨터에 비해 조금은 어렵기에, 그 안에서 더욱 흥미진진한 논의를 시작할 수 있다. 이제부터 그 논의의 출발점인 큐비트(Qubit)에 대해 알아보자.</p> <h2 id="큐비트-qubit">큐비트 (Qubit)</h2> <p>일반적인 컴퓨터와는 달리, 양자컴퓨터에서는 정보처리의 기본 단위로 <strong>큐비트(Qubit)</strong>를 사용한다. 따라서 양자컴퓨터가 정확하게 무엇인지, 깊이있게 이해하기 위해서는 먼저 큐비트를 잘 이해해야 한다. 이것은 고전 컴퓨터를 이해하기 위해 이진수를 숙달해야 하는 것과 같은 이치이다.</p> <h3 id="큐비트의-정의">큐비트의 정의</h3> <p>큐비트는 양자 비트(Quantum Bit)의 줄임말로, <strong>$0$ 또는 $1$이라고 부르는 두 상태의 양자역학적인 중첩(superposition)을 말한다.</strong> 측정(measurement)을 통해, 중첩 상태에서 벗어나 $0$ 또는 $1$ 중 하나의 값으로 결정된다.</p> <p>엄밀하지는 않지만, 동전이 책상 위에서 빠르게 회전하고 있는 상황을 상상하고, 동전을 손바닥으로 내리쳐서 멈췄을 때 윗면이 동전의 앞면인지 뒷면인지 관찰하는 것처럼 이해하면 (초반에는) 도움이 된다. 고전 비트와 비교하자면 아래와 같다:</p> <table> <thead> <tr> <th>구분</th> <th>고전 비트</th> <th>큐비트</th> </tr> </thead> <tbody> <tr> <td>상태</td> <td>$0$ 또는 $1$ (둘 중 하나)</td> <td>$\alpha\ket{0} + \beta\ket{1}$ (중첩 상태)</td> </tr> <tr> <td>측정 전</td> <td>항상 확정된 값</td> <td>확률적 중첩</td> </tr> <tr> <td>측정</td> <td>값 확인</td> <td>중첩 붕괴, $0$ 또는 $1$로 확정</td> </tr> <tr> <td>표현</td> <td>1개의 실수 (0 또는 1)</td> <td>2개의 복소수 ($\alpha, \beta$)</td> </tr> <tr> <td> </td> <td> </td> <td> </td> </tr> </tbody> </table> <h3 id="큐비트의-수학적-표현">큐비트의 수학적 표현</h3> <p>양자컴퓨팅에서는 상태 $0$과 $1$을 조금 화려하게 $\ket{0}$과 $\ket{1}$로 쓰고, 읽을 때는 “켓 0”, “켓 1”이라고 읽는다. 그리고 이들을 중첩시킬 때는 각각의 상태에 적절한 수를 곱해서 더하는 것으로 표현한다:</p> \[\ket{q}=\alpha\ket{0}+\beta\ket{1}\] <p>이것이 선형대수학에서 자주 등장하는 <strong>선형 결합(linear combination)</strong>의 개념이다. 2차원 평면 상의 벡터 $\mathbf{v}$를 $x$축 방향 단위 벡터 $\mathbf{i}$와 $y$축 방향 단위 벡터 $\mathbf{j}$의 선형 결합 $\mathbf{v}=x\mathbf{i}+y\mathbf{j}$로 표현하듯, 큐비트 역시도 상태 $\ket{0}$과 상태 $\ket{1}$의 선형 결합으로 표현할 수 있다. 앞으로는 ${\ket{0}, \ket{1}}$을 서로 수직인 두 단위 벡터처럼 생각해주기를 바란다.</p> <h4 id="벡터-표기법">벡터 표기법</h4> <p>벡터는 여러 수의 묶음, 즉 순서쌍으로도 이해할 수 있다. 큐비트 역시도 두 수 $\alpha,\:\beta$의 순서쌍으로 표현할 수 있기 때문에 2차원 벡터이다. 여기서 $\ket{0}=\begin{bmatrix} 1 \\ 0\end{bmatrix}$, $\ket{1}=\begin{bmatrix} 0 \\ 1\end{bmatrix}$로 정의하면 아래처럼 표현하는 것도 가능하다:</p> \[\begin{align*} \ket{q}=\alpha \ket{0} + \beta \ket{1}=\begin{bmatrix} \alpha\\\beta \end{bmatrix} \end{align*}\] <h2 id="예시로-알아보는-큐비트">예시로 알아보는 큐비트</h2> <p>아래의 $\ket{q_1}, \ket{q_2}, \ket{q_3}$는 모두 큐비트를 나타내는 벡터들이다:</p> \[\begin{align}\ket{q_1}&amp;=\frac{1}{\sqrt{2}}\ket0+\frac{i}{\sqrt{2}}\ket1=\frac{1}{\sqrt{2}} \begin{bmatrix} 1 \\ i \end{bmatrix} \\ \ket{q_2}&amp;=\frac{i}{\sqrt{3}}\ket0+\sqrt{\frac{2}{3}}\ket1=\frac{1}{\sqrt{3}} \begin{bmatrix} i \\ \sqrt{2} \end{bmatrix} \\ \ket{q_3}&amp;=\frac{1}{2}(1+i)\ket0 + \frac{1}{2}(1-i)\ket1=\frac{1}{2}\begin{bmatrix}1+i \\ 1-i \end{bmatrix}\end{align}\] <p>식을 2분 정도 지그시 관찰해보기를 바란다.</p> <p>관찰하다보면, 다소 이상한 점을 발견했을 것이다 - 허수 $i$가 왜 벡터 안에 들어 있는 것인가? 그 이유는 큐비트가 <strong>복소 벡터 공간(Complex Vector Space)</strong>의 원소이기 때문이다. 즉, 큐비트가 기본적으로 $(복소수, 복소수)$의 형태를 가진다.</p> <p>큐비트가 복소 벡터 공간의 원소라는 사실은 큐비트가 단순하게 “$0$과 $1$ 사이의 그 무언가”보다는 조금 더 많은 의미를 담고 있음을 시사한다. 근데 또 재밌는 것은, 큐비트가 $(복소수, 복소수)$의 형태라면 각 복소수는 $a + bi$의 형태로 나타나기 때문에 실수인 변수 $4$개를 써서 4차원 공간 상의 점으로 표현해야 할 것 같지만, <strong>실제로는 경도와 위도를 이용하여 구면 위의 점으로 표현한다는 것이다</strong>. 아래와 같이, 큐비트의 상태를 표현하기 위한 구면을 블로흐 구면(Bloch Sphere)이라고 한다.</p> <p><img src="/assets/img/blog/qubit/untitled_qubit-understanding.png" alt="블로흐 구면 (Bloch Sphere)"/> <em>그림: 블로흐 구면 - 큐비트 상태를 3차원 구면 위의 점으로 표현</em></p> <h2 id="두-가지-핵심-질문">두 가지 핵심 질문</h2> <p>여기까지 해서 두 가지 정도의 의문이 들 수 있겠다:</p> <ol> <li><strong>큐비트가 $(복소수, 복소수)$면 실수 변수 $4$개를 써야 표현이 가능할 것 같은데, 큐비트를 구면 위의 점으로 표현할 수 있는 이유는 무엇일까?</strong></li> <li><strong>애초에 큐비트를 표현하는데 복소수가 왜 필요한걸까?</strong></li> </ol> <p>이 두 질문은 서로 밀접하게 연관되어 있다. 순서대로 답해보자.</p> <h3 id="질문-1-큐비트를-구면-위의-점으로-표현할-수-있는-이유">질문 1: 큐비트를 구면 위의 점으로 표현할 수 있는 이유</h3> <p>우선은 두번째 질문에 대한 답변은 잠시 뒤로 미루고, 첫번째 질문에 집중해보자. 큐비트를 나타내기 위해서 실변수 두 개면 충분하다는데 그 이유가 뭘까?</p> <p>그 이유는 지금까지 언급하지 않은 두 개의 <strong>제약 조건(constraint)</strong>에 의해, 필요한 변수의 개수가 줄어들었기 때문이다. 여기서 첫번째 제약 조건은 확률의 <strong>정규화(Normalization)</strong>와 관련이 있고, 두번째 제약 조건은 <strong>전역 위상(Global phase)</strong>과 관련되어 있다.</p> <p>위의 내용을 논하려면 복소 계수의 의미에 대해서 이해해야 한다. 큐비트의 정의에서 $\alpha$는 무엇을 의미하고 $\beta$는 무엇을 의미할까? $\alpha$는 $\ket{0}$과 $\ket{1}$의 선형 결합에서 $\ket{0}$ 앞에 붙은 계수이다. 그렇기 때문에 $\alpha$의 값이 “커진다면”, 큐비트에서 상태 $\ket{0}$이 차지하는 비중이 늘어난다는 뜻이다. 즉, 큐비트가 상태 $\ket{0}$으로 측정될 확률이 커진다는 것을 의미한다.</p> <p>그렇다면 복소수의 “크기”는 어떻게 표현할까? 답은 간단하다: 복소수의 절댓값을 이용하면 된다. 큐비트를 측정했을 시 상태 $\ket{0}$ 또는 $\ket{1}$이 나올 확률은 각 상태 앞에 붙은 복소계수의 절댓값의 제곱이다. 이를 본의 규칙(Born’s Rule)이라 부른다:</p> <blockquote> <p><strong>본의 규칙 (Born’s Rule)</strong></p> <p>큐비트 $\ket{q}=\alpha\ket{0}+\beta\ket{1}$에 대해, 측정 이후 큐비트의 상태는 $\ket{0}$ 또는 $\ket{1}$이며:</p> <ul> <li>$\ket{0}$으로 측정될 확률: $P(0) = |\alpha|^2$</li> <li>$\ket{1}$로 측정될 확률: $P(1) = |\beta|^2$</li> </ul> </blockquote> <p>이렇게 앞의 복소 계수가 각 상태의 측정 확률을 의미한다는 것을 알고 나면, 정규화 조건을 적용할 수 있다. 즉, 입자는 반드시 $\ket{0}$ 또는 $\ket{1}$로 측정되어야 하므로, 두 발견 확률을 더하면 $1$이 되어야 한다. 따라서 아래 식을 얻는다:</p> \[\begin{equation} |\alpha| ^2 + |\beta| ^2=1 \end{equation}\] <p>이것이 첫번째 제약조건이다. $\alpha = \alpha_1+\alpha_2 i$, $\beta = \beta_1 + \beta_2 i$라 두면 아래와 같이 변형할 수 있다.</p> \[\begin{equation} \alpha_1^2+\alpha_2^2+\beta_1^2+\beta_2^2=1 \end{equation}\] <p>아래의 원의 방정식과 구의 방정식, 그리고 식 $(6)$을 함께 보자.</p> \[\begin{aligned}\textrm{원의 방정식:}&amp;\;\;x^2+y^2=1 \\ \textrm{구의 방정식:}&amp;\;\;x^2+y^2+z^2=1 \end{aligned}\] <p>식 $(6)$이 특별하게 느껴지지 않는가? 원의 방정식과 구의 방정식과 함께 보면 식 $(6)$이 4차원 공간 상의 구, 즉 초구(Hypersphere)의 방정식이라는 사실을 알아차릴 수 있다. 제약 조건(=등식)이 추가될 때마다 자유도는 줄어든다. 즉, 방금 큐비트는 $2$차원 복소 벡터이기에 실변수로는 4차원인 것 같으면서도, 제약 조건에 의해 1개의 자유도가 날아가면서 3개의 변수만으로도 표현할 수 있게 된 것이다.</p> <p>그러나 여전히 식의 개수가 부족하다. 자유도가 4개에서 3개로 줄어들긴 했지만, 구면 위에서 표현하려면 제약 조건이 한 개가 더 필요한 상황이다. <strong>마지막 제약 조건은 어디에서 오는걸까?</strong> 이 질문에 대한 답은 우리의 두번째 질문이었던 “큐비트를 복소수로 표현해야 하는 이유”에 대해 답하고 나면 명쾌하게 답할 수 있으니, 먼저 두번째 질문에 답해보자.</p> <h3 id="질문-2-큐비트를-복소수로-표현해야만-하는-이유">질문 2: 큐비트를 복소수로 표현해야만 하는 이유</h3> <p>이제 두번째 질문에 답해보자. 왜 큐비트는 복소수로 표현해야만 하는가?</p> <p>두괄식으로 이야기하자면 <strong>“크기와 위상을 동시에 표현하기 위해서”</strong>이다. 여기서 위상(phase)이 무엇인지 이해하려면 (1) 반대 위상($180°$ 위상차)를 가지는 두 복소수의 예시와 (2) $90°$의 위상차를 가지는 두 복소수의 예시를 살펴보면 도움이 된다.</p> <p>먼저 복소수에 관한 몇 가지 사실을 정리해보자. 오일러의 공식(Euler’s formula)에 의해, 임의의 복소수 $z=a+bi$는 그 크기 $R=\sqrt{a^2+b^2}$로 나누었을 때 편각 $\theta$가 존재하여</p> \[z/R=(a/R)+i(b/R)=\cos{\theta}+i\sin{\theta}=e^{i\theta}\] <p>를 만족한다. 양변에 $R$을 곱하면 임의의 복소수는 $z=Re^{i\theta}$의 꼴로 표현할 수 있으며, 이는 크기와 위상을 동시에 나타낸 것이다.</p> <h4 id="위상차의-예시">위상차의 예시</h4> <p>예를 들어 다음 세 복소수를 생각해보자: \(\begin{align} z_0&amp;=1+i = \sqrt{2}e^{i\pi/4} \\ z_1&amp;=-1-i = \sqrt{2}e^{i5\pi/4} = \sqrt{2}e^{i\pi/4} \cdot e^{i\pi} \\ z_2&amp;=-1+i = \sqrt{2}e^{i3\pi/4} = \sqrt{2}e^{i\pi/4} \cdot e^{i\pi/2} \end{align}\)</p> <p>여기서 $z_1 = -z_0$이므로 $z_0$와 $z_1$은 $180°$ 위상차를 가지고, $z_2 = iz_0$이므로 $z_0$와 $z_2$는 $90°$ 위상차를 가진다.</p> <p>이제 큐비트에서 이 개념이 어떻게 사용되는지 보자. 다음 큐비트를 생각해보자: \(\ket{q} = (1+i)\ket{0} + (-1-i)\ket{1} = z_0\ket{0} + z_1\ket{1}\)</p> <p>이 큐비트를 벡터로 쓰면: \(\begin{align*} \ket{q} = \begin{bmatrix} 1+i \\ -1-i \end{bmatrix} = \begin{bmatrix} \sqrt{2}e^{i\pi/4} \\ \sqrt{2}e^{i5\pi/4} \end{bmatrix} \end{align*}\)</p> <p>극좌표 형식에서 공통 인수를 빼내면: \(\begin{align*} \ket{q} = e^{i\pi/4}\begin{bmatrix} \sqrt{2} \\ \sqrt{2}e^{i\pi} \end{bmatrix} = e^{i\pi/4}\begin{bmatrix} \sqrt{2} \\ -\sqrt{2} \end{bmatrix} \end{align*}\)</p> <p>여기서 흥미로운 사실을 발견할 수 있다. 전체 상태에 공통으로 $e^{i\pi/4}$가 곱해져 있다. 이를 <strong>전역 위상(Global Phase)</strong>이라 부른다.</p> <h4 id="정규화-조건-적용">정규화 조건 적용</h4> <p>그런데 위 상태는 아직 정규화되지 않았다. 확률의 합을 계산하면: \(|\sqrt{2}|^2 + |-\sqrt{2}|^2 = 2 + 2 = 4 \neq 1\)</p> <p>따라서 $\sqrt{4} = 2$로 나눠서 정규화해야 한다: \(\begin{align*} \ket{q}_{\text{normalized}} = e^{i\pi/4} \frac{1}{2}\begin{bmatrix} \sqrt{2} \\ -\sqrt{2} \end{bmatrix} = e^{i\pi/4} \frac{1}{\sqrt{2}}\begin{bmatrix} 1 \\ -1 \end{bmatrix} \end{align*}\)</p> <p>이제 정규화 조건을 확인하면: \(\left|\frac{1}{\sqrt{2}}\right|^2 + \left|\frac{-1}{\sqrt{2}}\right|^2 = \frac{1}{2} + \frac{1}{2} = 1 \;\checkmark\)</p> <p>전역 위상을 무시하면, 이 큐비트는 블로흐 구면의 적도 위에 있는 $\ket{-} = \frac{1}{\sqrt{2}}(\ket{0} - \ket{1})$ 상태임을 알 수 있다.</p> <h3 id="전역-위상의-의미">전역 위상의 의미</h3> <p>전역 위상이 중요한 이유는 <strong>물리적으로 관측 불가능하다</strong>는 것이다. 왜냐하면 측정 확률은 복소계수의 절댓값의 제곱으로 결정되는데, 전역 위상 $e^{i\theta}$의 절댓값은 항상 $1$이기 때문이다:</p> \[|e^{i\theta}|^2 = (\cos\theta + i\sin\theta)(\cos\theta - i\sin\theta) = \cos^2\theta + \sin^2\theta = 1\] <p>따라서 $\ket{q}$와 $e^{i\theta}\ket{q}$는 물리적으로 동일한 상태를 나타낸다. 이것이 우리가 찾던 두번째 제약 조건이다!</p> <p>큐비트 $\ket{q}=\alpha\ket{0}+\beta\ket{1}$을 생각해보자. $\alpha$와 $\beta$를 극좌표로 표현하면: \(\begin{align} \ket{q}&amp;=|\alpha|e^{i\theta_\alpha}\ket{0}+|\beta|e^{i\theta_\beta}\ket{1} \\ &amp;=e^{i\theta_\alpha}\left(|\alpha|\ket{0}+|\beta|e^{i(\theta_\beta-\theta_\alpha)}\ket{1}\right) \end{align}\)</p> <p>여기서 $e^{i\theta_\alpha}$는 전역 위상이므로 무시할 수 있다. 따라서 우리는 실제로 다음 세 개의 변수만 있으면 된다:</p> <ul> <li>$|\alpha|$ (크기 1)</li> <li>$|\beta|$ (크기 1)</li> <li>$\theta_\beta - \theta_\alpha$ (상대 위상)</li> </ul> <p>그런데 정규화 조건 $|\alpha|^2 + |\beta|^2 = 1$에 의해 $|\alpha|$와 $|\beta|$는 독립적이지 않다. 따라서 실제로 필요한 변수는 <strong>2개</strong>뿐이다!</p> <p>이것이 바로 큐비트를 블로흐 구면(Bloch Sphere)이라는 2차원 구면 위의 점으로 표현할 수 있는 이유이다. 구면 위의 한 점은 경도와 위도, 즉 두 개의 각도 $\theta$(극각)와 $\phi$(방위각)로 나타낼 수 있다:</p> \[\ket{q} = \cos\frac{\theta}{2}\ket{0} + e^{i\phi}\sin\frac{\theta}{2}\ket{1}\] <p>여기서 $\theta \in [0, \pi]$, $\phi \in [0, 2\pi)$이다.</p> <h4 id="블로흐-구면-위의-중요한-상태들">블로흐 구면 위의 중요한 상태들</h4> <p>블로흐 구면에서 몇 가지 중요한 큐비트 상태들을 살펴보자:</p> <p><strong>북극과 남극 (Z축)</strong> \(\begin{align} \ket{0} &amp;= \begin{bmatrix} 1 \\ 0 \end{bmatrix} \quad (\theta=0) \\ \ket{1} &amp;= \begin{bmatrix} 0 \\ 1 \end{bmatrix} \quad (\theta=\pi) \end{align}\)</p> <p><strong>적도 위의 상태들 (X-Y 평면)</strong> \(\begin{align} \ket{+} &amp;= \frac{1}{\sqrt{2}}(\ket{0}+\ket{1}) = \frac{1}{\sqrt{2}}\begin{bmatrix} 1 \\ 1 \end{bmatrix} \quad (\theta=\pi/2, \phi=0) \\ \ket{-} &amp;= \frac{1}{\sqrt{2}}(\ket{0}-\ket{1}) = \frac{1}{\sqrt{2}}\begin{bmatrix} 1 \\ -1 \end{bmatrix} \quad (\theta=\pi/2, \phi=\pi) \\ \ket{+i} &amp;= \frac{1}{\sqrt{2}}(\ket{0}+i\ket{1}) = \frac{1}{\sqrt{2}}\begin{bmatrix} 1 \\ i \end{bmatrix} \quad (\theta=\pi/2, \phi=\pi/2) \\ \ket{-i} &amp;= \frac{1}{\sqrt{2}}(\ket{0}-i\ket{1}) = \frac{1}{\sqrt{2}}\begin{bmatrix} 1 \\ -i \end{bmatrix} \quad (\theta=\pi/2, \phi=3\pi/2) \end{align}\)</p> <p>이들 상태는 각각 X축, Y축 방향의 측정 기저로 사용되며, 양자 알고리즘에서 자주 등장한다.</p> <h3 id="복소수와-양자-간섭">복소수와 양자 간섭</h3> <p>앞서 큐비트를 복소수로 표현해야 하는 이유를 “크기와 위상을 동시에 표현하기 위해서”라고 했다. 이제 그 이유를 더 깊이 이해해보자.</p> <p>단순히 확률만 표현하려면 실수만으로도 충분할 것이다. 하지만 양자컴퓨팅에서는 <strong>양자 간섭(Quantum Interference)</strong> 현상을 활용한다. 두 경로를 통해 같은 상태에 도달할 때, 위상이 같으면 보강 간섭(constructive interference)이 일어나 확률이 증가하고, 위상이 반대면 상쇄 간섭(destructive interference)이 일어나 확률이 감소한다.</p> <h4 id="간섭의-예시">간섭의 예시</h4> <p>앞서 정의한 복소수 $z_0 = 1+i$와 $z_1 = -1-i$를 다시 보자. 이 두 복소수는 $180°$ 위상차를 가지고 있다 ($z_1 = -z_0$). 만약 양자 연산을 통해 이 두 진폭이 더해진다면 $z_0 + z_1 = 0$이 되어 완전히 상쇄된다.</p> <p>반면 $z_0 = 1+i$와 $z_2 = -1+i$는 $90°$ 위상차를 가진다 ($z_2 = iz_0$). 이들을 더하면 $z_0 + z_2 = 2i$로 소멸하지 않는다.</p> <p>이러한 <strong>위상 정보를 표현하고 간섭을 활용하기 위해서는 복소수가 필수적</strong>이다. 실수만으로는 위상 정보를 담을 수 없고, 따라서 양자 간섭이라는 강력한 현상을 활용할 수 없다. 바로 이것이 양자컴퓨터가 특정 문제에서 고전 컴퓨터보다 빠를 수 있는 근본적인 이유 중 하나이다.</p> <h2 id="심화-실제-양자-시스템과-큐트리트">심화: 실제 양자 시스템과 큐트리트</h2> <blockquote> <p><strong>💡 이 섹션은 심화 내용입니다</strong><br/> 큐비트의 기본 개념만 이해하고 싶다면 이 섹션을 건너뛰어도 좋습니다.</p> </blockquote> <h3 id="실제-양자-시스템에서의-에너지-준위">실제 양자 시스템에서의 에너지 준위</h3> <p>지금까지 큐비트를 $\ket{0}$과 $\ket{1}$의 2준위 시스템으로 다뤘지만, 실제 물리 시스템(초전도 큐비트, 이온 트랩, 원자 등)에서는 $\ket{0}$, $\ket{1}$ 외에도 <strong>$\ket{2}$, $\ket{3}$, $\ket{4}$, … 등의 고차 에너지 준위가 항상 존재</strong>한다.</p> <p>예를 들어, 조화진동자(harmonic oscillator)의 에너지 준위는 등간격이다: \(E_n = \hbar\omega\left(n + \frac{1}{2}\right), \quad n = 0, 1, 2, 3, \ldots\)</p> <p>이 경우 $\ket{0} \rightarrow \ket{1}$ 전이와 $\ket{1} \rightarrow \ket{2}$ 전이의 에너지 차이가 같다 ($\hbar\omega$). 따라서 $\ket{0}$과 $\ket{1}$에만 작용하려던 마이크로파가 의도치 않게 $\ket{2}$ 상태도 들뜨게 할 수 있다.</p> <h4 id="비조화-진동자-설계">비조화 진동자 설계</h4> <p>이 문제를 해결하기 위해 <strong>비조화 진동자(anharmonic oscillator)</strong>를 설계한다. 예를 들어, 초전도 큐비트는 조셉슨 접합(Josephson junction)을 사용하여 비조화성을 도입한다:</p> \[E_n \approx \hbar\omega_0 n - \frac{\hbar\alpha}{2}n(n-1)\] <p>여기서 $\alpha &gt; 0$는 비조화성(anharmonicity)이다. 이렇게 하면:</p> <ul> <li>$\ket{0} \leftrightarrow \ket{1}$ 전이 주파수: $\omega_{01} = \omega_0$</li> <li>$\ket{1} \leftrightarrow \ket{2}$ 전이 주파수: $\omega_{12} = \omega_0 - \alpha$</li> </ul> <p>두 전이 주파수가 달라지므로, $\omega_{01}$에 공명하는 제어 펄스를 사용하면 $\ket{0}$과 $\ket{1}$만 선택적으로 제어할 수 있다.</p> <blockquote> <p><strong>중요</strong>: 고차 준위는 완전히 사라지지 않으며, 항상 존재한다. 다만 에너지 간격을 다르게 만들어 선택적 제어가 가능하도록 한다. 일부 연구에서는 이러한 고차 준위를 적극 활용하기도 한다.</p> </blockquote> <h3 id="큐트리트-qutrit">큐트리트 (Qutrit)</h3> <p>고차 상태의 존재를 이해하기 위해, 세 상태 $\ket{0}, \ket{1}, \ket{2}$의 중첩인 <strong>큐트리트(Qutrit)</strong>를 살펴보자. 큐트리트는 3준위 양자 시스템으로:</p> \[\ket{q} = \alpha\ket{0} + \beta\ket{1} + \gamma\ket{2}\] <p>앞서 사용한 복소수 $z_0, z_1, z_2$로 예시를 만들면: \(\ket{q} = z_0\ket{0} + z_1\ket{1} + z_2\ket{2} = (1+i)\ket{0} + (-1-i)\ket{1} + (-1+i)\ket{2}\)</p> <p>벡터 표기로 쓰고 극좌표 형식으로 변환하면: \(\begin{align} \ket{q} &amp;= \begin{bmatrix} 1+i \\ -1-i \\ -1+i \end{bmatrix} = \begin{bmatrix} \sqrt{2}e^{i\pi/4} \\ \sqrt{2}e^{i5\pi/4} \\ \sqrt{2}e^{i3\pi/4} \end{bmatrix} \\ &amp;= e^{i\pi/4}\begin{bmatrix} \sqrt{2} \\ \sqrt{2}e^{i\pi} \\ \sqrt{2}e^{i\pi/2} \end{bmatrix} = e^{i\pi/4}\begin{bmatrix} \sqrt{2} \\ -\sqrt{2} \\ \sqrt{2}i \end{bmatrix} \end{align}\)</p> <p>큐비트와 마찬가지로 전역 위상 $e^{i\pi/4}$가 나타난다.</p> <h4 id="정규화">정규화</h4> <p>이 상태도 정규화되지 않았다. 확률의 합을 계산하면: \(|\sqrt{2}|^2 + |-\sqrt{2}|^2 + |\sqrt{2}i|^2 = 2 + 2 + 2 = 6 \neq 1\)</p> <p>따라서 $\sqrt{6}$로 나눠서 정규화한다: \(\begin{align*} \ket{q}_{\text{normalized}} = e^{i\pi/4} \frac{1}{\sqrt{6}}\begin{bmatrix} \sqrt{2} \\ -\sqrt{2} \\ \sqrt{2}i \end{bmatrix} = e^{i\pi/4} \sqrt{\frac{1}{3}}\begin{bmatrix} 1 \\ -1 \\ i \end{bmatrix} \end{align*}\)</p> <p>확인: \(\left|\sqrt{\frac{1}{3}}\right|^2 + \left|-\sqrt{\frac{1}{3}}\right|^2 + \left|i\sqrt{\frac{1}{3}}\right|^2 = \frac{1}{3} + \frac{1}{3} + \frac{1}{3} = 1 \;\checkmark\)</p> <p>전역 위상을 무시하면, 각 상태가 측정될 확률은 모두 $\frac{1}{3}$로 동일하다.</p> <h3 id="연습-문제-큐트리트의-자유도">연습 문제: 큐트리트의 자유도</h3> <p>큐비트에 대해 배운 정규화 조건과 전역 위상 개념을 큐트리트에 확장해보자.</p> <p><strong>문제</strong>: 세 상태 $\ket{0}, \ket{1}, \ket{2}$의 중첩인 큐트리트 $\ket{q} = \alpha\ket{0} + \beta\ket{1} + \gamma\ket{2}$를 표현하는데 몇 개의 <strong>실수 매개변수</strong>가 필요한가?</p> <p><strong>힌트</strong></p> <p>다음 질문들을 순서대로 생각해보자:</p> <ol> <li>큐트리트는 몇 차원 복소 벡터인가?</li> <li>초기에는 몇 개의 실수 변수가 필요한가?</li> <li>정규화 조건은 어떻게 되는가? 이것이 자유도를 몇 개 줄이는가?</li> <li>전역 위상은 여전히 물리적으로 무관한가? 이것이 자유도를 몇 개 줄이는가?</li> </ol> <p><strong>답안 및 풀이</strong></p> <p><strong>1단계: 초기 자유도</strong> 큐트리트는 3차원 복소 벡터이므로 3개의 복소수 $(\alpha, \beta, \gamma)$가 필요하다.<br/> 각 복소수는 2개의 실수로 표현되므로: <strong>6개의 실변수</strong></p> <p><strong>2단계: 정규화 조건</strong> 측정 확률의 합이 1이어야 하므로: \(|\alpha|^2 + |\beta|^2 + |\gamma|^2 = 1\) 이 조건이 1개의 등식이므로: <strong>-1 자유도</strong></p> <p><strong>3단계: 전역 위상</strong> $\ket{q}$와 $e^{i\theta}\ket{q}$는 물리적으로 동일한 상태이므로: <strong>-1 자유도</strong></p> <p><strong>최종 답</strong>: \(6 - 1 - 1 = \boxed{4} \text{ 개의 실수 매개변수}\)</p> <p><strong>일반화</strong>: $n$차원 양자 시스템(qudit)은 <strong>$2n - 2$개의 실수 매개변수</strong>로 표현할 수 있다.</p> <table> <thead> <tr> <th>시스템</th> <th>차원 $n$</th> <th>실수 매개변수</th> <th>비고</th> </tr> </thead> <tbody> <tr> <td>큐비트 (Qubit)</td> <td>2</td> <td>$2(2) - 2 = 2$</td> <td>블로흐 구면 ($\theta, \phi$) ✓</td> </tr> <tr> <td>큐트리트 (Qutrit)</td> <td>3</td> <td>$2(3) - 2 = 4$</td> <td>4차원 공간</td> </tr> <tr> <td>큐쿼트 (Ququart)</td> <td>4</td> <td>$2(4) - 2 = 6$</td> <td>6차원 공간</td> </tr> <tr> <td>일반 Qudit</td> <td>$n$</td> <td>$2n - 2$</td> <td>$(2n-2)$차원 공간</td> </tr> <tr> <td> </td> <td> </td> <td> </td> <td> </td> </tr> </tbody> </table> <p><strong>물리적 의미</strong>: 큐트리트는 4차원 공간의 점으로 표현되므로 블로흐 구면처럼 3차원으로 시각화하기 어렵다. 이러한 이유로 양자컴퓨터에서는 주로 2준위 시스템(큐비트)을 사용한다. 그러나 최근에는 <strong>qutrit 양자컴퓨팅</strong> 연구도 활발하다. 큐트리트는 같은 개수의 물리적 객체로 더 많은 정보를 저장할 수 있으며, 일부 양자 알고리즘에서 효율성이 더 높을 수 있다.</p> <h2 id="측정의-예시">측정의 예시</h2> <p>큐비트의 개념을 완전히 이해하기 위해, 간단한 측정 예시를 살펴보자.</p> <p>큐비트 $\ket{q} = \frac{1}{\sqrt{2}}\ket{0} + \frac{1}{\sqrt{2}}\ket{1}$ (블로흐 구면의 적도 위 $\ket{+}$ 상태)를 생각해보자.</p> <p>본의 규칙에 의해:</p> <ul> <li>$\ket{0}$으로 측정될 확률: $\left|\frac{1}{\sqrt{2}}\right|^2 = \frac{1}{2}$</li> <li>$\ket{1}$로 측정될 확률: $\left|\frac{1}{\sqrt{2}}\right|^2 = \frac{1}{2}$</li> </ul> <p>이 큐비트를 측정하면 <strong>50%의 확률로 $\ket{0}$, 50%의 확률로 $\ket{1}$이 관측</strong>된다. 측정 전에는 두 상태의 중첩이었지만, 측정 후에는 둘 중 하나로 확정된다.</p> <p>다른 예시로, $\ket{q’} = \frac{1}{2}\ket{0} + \frac{\sqrt{3}}{2}\ket{1}$을 생각해보자:</p> <ul> <li>$\ket{0}$으로 측정될 확률: $\left|\frac{1}{2}\right|^2 = \frac{1}{4} = 25\%$</li> <li>$\ket{1}$로 측정될 확률: $\left|\frac{\sqrt{3}}{2}\right|^2 = \frac{3}{4} = 75\%$</li> </ul> <p>이처럼 계수의 절댓값 크기에 따라 측정 확률이 결정된다.</p> <blockquote> <p><strong>중요</strong>: 측정은 큐비트의 상태를 <strong>파괴</strong>한다. 측정 전 중첩 상태에 있던 큐비트는 측정 후 $\ket{0}$ 또는 $\ket{1}$로 확정되며, 원래의 중첩 상태로 돌아갈 수 없다.</p> </blockquote> <h2 id="결론">결론</h2> <p>지금까지 양자컴퓨팅의 기본 단위인 큐비트에 대해 알아보았다. 핵심 내용을 정리하면:</p> <h3 id="핵심-요약">핵심 요약</h3> <p><strong>1. 중첩 (Superposition)</strong></p> <ul> <li>큐비트는 $\ket{0}$과 $\ket{1}$의 양자 중첩 상태: $\ket{q}=\alpha\ket{0}+\beta\ket{1}$</li> <li>고전 비트는 0 또는 1, 큐비트는 “0과 1의 조합”</li> </ul> <p><strong>2. 복소 벡터 공간</strong></p> <ul> <li>큐비트는 2차원 복소 벡터 공간의 원소</li> <li>복소수는 <strong>위상 정보</strong>를 담아 양자 간섭 현상을 가능하게 함</li> </ul> <p><strong>3. 본의 규칙 (Born’s Rule)</strong></p> <ul> <li>측정 확률: $P(0)=|\alpha|^2$, $P(1)=|\beta|^2$</li> <li>정규화 조건: $|\alpha|^2 + |\beta|^2 = 1$</li> </ul> <p><strong>4. 블로흐 구면 (Bloch Sphere)</strong></p> <ul> <li>4개의 실변수 → 정규화 조건과 전역 위상 무관성 → 2개의 매개변수 ($\theta$, $\phi$)</li> <li>큐비트는 3차원 구면 위의 점으로 시각화 가능</li> <li>일반적으로 $n$차원 양자 시스템은 $2n-2$개의 실수 매개변수로 표현 (심화 섹션 참고)</li> </ul> <p><strong>5. 양자 간섭</strong></p> <ul> <li>위상이 같으면 보강 간섭 (확률 증가)</li> <li>위상이 반대면 상쇄 간섭 (확률 감소)</li> <li>이것이 양자컴퓨터의 계산 능력의 핵심</li> </ul> <h3 id="큐비트의-의의">큐비트의 의의</h3> <p>큐비트는 고전 비트보다 복잡하지만, 바로 그 복잡성이 양자컴퓨터의 강력한 계산 능력의 원천이 된다.</p> <ul> <li><strong>중첩</strong>: 여러 상태를 동시에 표현</li> <li><strong>간섭</strong>: 원하는 답의 확률 증폭, 잘못된 답의 확률 감소</li> <li><strong>얽힘</strong> (Entanglement, 다음 글에서): 여러 큐비트 간의 상관관계</li> </ul> <p>이 세 가지 양자역학적 현상을 활용하여, 양자컴퓨터는 특정 문제들(인수분해, 데이터베이스 검색, 양자 시뮬레이션 등)에서 고전 컴퓨터를 능가하는 성능을 보일 수 있다.</p>]]></content><author><name></name></author><category term="quantum"/><category term="quantum-computing"/><category term="qubits"/><category term="bloch-sphere"/><category term="complex-numbers"/><category term="physics"/><category term="korean"/><summary type="html"><![CDATA[양자컴퓨팅의 기본: 큐비트와 블로흐 구면, 그리고 복소수의 필요성]]></summary></entry><entry xml:lang="en"><title type="html">Toward a Unified Theory</title><link href="https://codingjang.github.io/blog/2025/information-compression-neural-networks-and-ai-for-science/" rel="alternate" type="text/html" title="Toward a Unified Theory"/><published>2025-10-11T05:00:00+00:00</published><updated>2025-10-11T05:00:00+00:00</updated><id>https://codingjang.github.io/blog/2025/information-compression-neural-networks-and-ai-for-science</id><content type="html" xml:base="https://codingjang.github.io/blog/2025/information-compression-neural-networks-and-ai-for-science/"><![CDATA[<p><em>This essay synthesizes ideas from ongoing research on information compression theory, neural network approximation, and AI for science. It is based on my (unorganized) research notes on AI for science, written in a mix of both Korean and English. The writing has been auto-generated by Claude 4.5 Sonnet, and has been reviewed and revised by myself. Special thanks to Hongchul Nam, Rocky Kim, Seunghwan Jang, and other collaborators for discussions on Gordon’s escape theorem, information bottleneck, and optimal transport approaches.</em></p> <p><em>EDIT: Title &amp; description edited on Oct 17, 2025</em></p> <h2 id="introduction-a-question-of-representation">Introduction: A Question of Representation</h2> <p>What does it mean to understand something? At its core, understanding requires finding an efficient representation—a way to capture the essence of a phenomenon while discarding irrelevant details. This principle appears everywhere: in how we communicate through language, how we compress data, and perhaps most intriguingly, in how neural networks learn.</p> <p>Consider two seemingly different compression algorithms. Huffman coding eliminates redundancy by representing frequently repeated characters with fewer bits—a lossless technique where no information is lost. JPEG compression, by contrast, removes high-frequency signals that humans cannot readily perceive, achieving much higher compression ratios at the cost of some information loss. Both succeed because they identify and exploit patterns: one in the statistics of character frequency, the other in the structure of human perception.</p> <p>Now consider a more provocative question: <strong>What if neural networks are performing a form of nonlinear compression?</strong></p> <p>It is well established that sufficiently deep neural networks can approximate arbitrary continuous functions—the universal approximation theorem. But here’s the twist: the number of weights needed to approximate a function within a given error bound might serve as a measure of that function’s intrinsic complexity. Just as Huffman coding reveals the statistical structure of text, and JPEG reveals the perceptual structure of images, perhaps neural network capacity reveals something fundamental about the information content of functions themselves.</p> <p>This observation opens a deeper question. In linear algebra, there exists a one-to-one correspondence between matrices and linear transformations—every linear function is, ultimately, just an arrangement of numbers. If this principle extends to nonlinear functions, then <strong>information compression theory and neural network approximation theory might be two facets of the same underlying phenomenon</strong>. The possibility of such a unification would not merely be elegant—it could fundamentally change how we understand learning, representation, and even scientific discovery itself.</p> <h2 id="intelligence-as-compression-the-principle-of-condensed-expression">Intelligence as Compression: The Principle of Condensed Expression</h2> <p>If compression algorithms reveal structure in data, perhaps intelligence itself is fundamentally about discovering and exploiting structure. I propose that <strong>a central function of intelligence is the generation of condensed expressions</strong>—representations that capture essential patterns while eliminating redundancy.</p> <p>This principle manifests at multiple levels:</p> <h3 id="level-1-statistical-redundancy">Level 1: Statistical Redundancy</h3> <p>The most basic form of condensation eliminates repetition. Just as Huffman coding represents frequent characters with fewer bits, saying “repeat ‘a’ 20 times” is more efficient than writing out “aaaaaaaaaaaaaaaaaaaa.” This isn’t merely about efficiency—it’s about recognizing that the pattern itself (repeated ‘a’) contains the essential information, not its mechanical expansion.</p> <h3 id="level-2-shared-knowledge-as-implicit-compression">Level 2: Shared Knowledge as Implicit Compression</h3> <p>Here’s a deeper insight: <strong>we can eliminate redundancy not just within a message, but between minds</strong>. When you and I communicate, we implicitly compress messages by omitting our shared knowledge. A single word—”home,” “danger,” “beautiful”—can invoke vast networks of shared experience and understanding without transmitting the underlying data.</p> <p>This explains phenomena that seem puzzling from a pure information-theoretic perspective:</p> <ul> <li>Why communication across cultural contexts is so difficult (different shared knowledge = different compression schemes)</li> <li>Why expert teams achieve seemingly telepathic coordination (extensive shared knowledge enables extreme compression)</li> <li>Why the same phrase can mean entirely different things to different people (decompression depends on the receiver’s knowledge base)</li> </ul> <h3 id="level-3-context-as-adaptive-compression">Level 3: Context as Adaptive Compression</h3> <p>Not all information is equally relevant. A waiter focuses on menu items, not customer names. JPEG compression discards high-frequency visual information that humans barely perceive. Both examples illustrate <strong>context-dependent compression</strong>—the ability to adaptively discard information based on its relevance to current goals.</p> <p>This suggests something profound: <strong>what counts as “information” is not absolute but goal-relative</strong>. The same physical stimulus contains different amounts of relevant information depending on what you’re trying to achieve. Intelligence, then, involves not just pattern recognition but pattern relevance assessment.</p> <h3 id="level-4-world-models-as-compressed-reality">Level 4: World Models as Compressed Reality</h3> <p>Finally, consider the grandest form of condensation: our internal models of reality. The universe is incomprehensibly complex—approximately $10^{80}$ atoms, each with position, momentum, quantum state. Yet our brains, with their roughly $10^{11}$ neurons and $10^{15}$ synapses, can predict, plan, and navigate this complexity.</p> <p>How? <strong>By learning a compressed representation</strong>—a world model that captures causal structure, regularities, and patterns while discarding the vast majority of microscopic details. From an evolutionary perspective, consciousness itself may have emerged as an adaptive compression algorithm: organisms that could efficiently represent absent prey, remember past events, and imagine future scenarios had survival advantages.</p> <p>Crucially, humans don’t just compress—we share compressed representations through language, enabling collective intelligence that transcends individual cognitive limits. A scientific theory is perhaps the ultimate condensed expression: a few equations capturing patterns that span countless observations.</p> <p>This multilevel view of intelligence-as-compression naturally leads us to ask: <strong>How do these principles manifest in artificial neural networks?</strong></p> <h2 id="neural-networks-as-nonlinear-basis-learners">Neural Networks as Nonlinear Basis Learners</h2> <p>The connection between compression and neural networks becomes clearer when we examine linear algebra through a compression lens. Consider two classical techniques:</p> <p><strong>Diagonalization</strong> finds a basis where a matrix becomes diagonal—representing the linear transformation with only diagonal entries. This is lossless: every bit of information is preserved, just reorganized for maximum parsimony.</p> <p><strong>Singular Value Decomposition (SVD)</strong> goes further: it identifies principal components ordered by importance. By truncating small singular values, we achieve lossy compression—trading perfect accuracy for massive dimension reduction.</p> <p>These aren’t just computational tricks. They reveal something fundamental: <strong>finding the right basis is equivalent to discovering compressible structure</strong>. Diagonalization finds a basis revealing perfect sparsity. SVD finds a basis revealing approximate low-rank structure.</p> <p>But here’s the limitation: these techniques only work for linear transformations. The world, however, is decidedly nonlinear.</p> <h3 id="the-nonlinear-generalization">The Nonlinear Generalization</h3> <p>This raises a tantalizing question: <strong>What would “SVD for nonlinear functions” look like?</strong></p> <p>I hypothesize that neural networks are precisely this generalization. Just as SVD learns an optimal linear basis for data compression, neural networks learn optimal nonlinear bases—hierarchical representations that progressively extract and compress task-relevant features. The network’s architecture and weights together define an adaptive, nonlinear coordinate system optimized for the task at hand.</p> <p>This perspective reframes fundamental questions in deep learning:</p> <ul> <li><strong>Network capacity</strong> → How much can we compress in this representation space?</li> <li><strong>Training</strong> → Finding the basis that maximizes compression of training data</li> <li><strong>Generalization</strong> → Whether the learned compression captures true underlying structure or merely memorizes noise</li> <li><strong>Transfer learning</strong> → Reusing a learned basis across related compression problems</li> </ul> <h3 id="toward-a-mathematical-framework">Toward a Mathematical Framework</h3> <p>To formalize this intuition, consider rate-distortion theory. For a matrix $X$ sampled from distribution $\mathcal{D}$ and compressed representation $\tilde{X}$ (e.g., quantized singular values):</p> \[\begin{aligned} &amp;\underset{p(\tilde{x}|x)}{\text{minimize}}\;I(X;\tilde{X})\\ &amp;\text{subject to} \; \left&lt; d(x,\tilde{x}) \right&gt;_{p(x,\tilde{x})}\le D \end{aligned}\] <p>For deterministic SVD, $p(\tilde{x}|x)$ is deterministic, so $I(X; \tilde{X})=H(\tilde{X})-H(\tilde{X}|X)=H(\tilde{X})$—we simply minimize the entropy of our representation. But introducing stochasticity creates an interesting tradeoff: randomness enables exploring alternative compressions, potentially discovering better representations at the cost of slightly higher mutual information.</p> <p>More ambitiously, we might extend this framework to nonlinear function spaces. <strong>The key challenge: how do we define “mutual information” between a function and its neural network approximation?</strong> Answering this could provide a rigorous foundation for understanding neural network capacity in information-theoretic terms, potentially unifying compression theory and approximation theory.</p> <h3 id="learning-task-adaptive-bases">Learning Task-Adaptive Bases</h3> <p>Here’s where the compression perspective reveals deeper structure. Consider not one task, but a distribution of related tasks—for instance, various manipulation tasks (sipping coffee, watering plants, opening doors) that share common sub-components like “grasping” and “moving smoothly.”</p> <p>A powerful insight emerges: <strong>the optimal representation for a task distribution should decompose tasks into shared, reusable components</strong>. This is meta-learning from a compression perspective.</p> <p>Given a distribution of tasks $\mathcal{D}$, where each sampled task $F \sim \mathcal{D}$ is a Lebesgue-integrable function from $\mathbb{R}^n$ to $\mathbb{R}^m$, and given the norm $|\cdot|$ defined by the inner product $\left&lt;f,g\right&gt;=\int_{\mathbb{R}^n}w(\mathbf{x}){f(\mathbf{x})\cdot g(\mathbf{x})} d\mathbf{x}$, what is the most efficient parametrized basis $\mathcal{B}_\theta = {f_1(\theta), f_2(\theta), \cdots,f_d(\theta) }$, i.e.,</p> \[\begin{align*} \underset{\theta \in \mathbb{R}^p} {\textrm{minimize}} \;\;\mathbb{E}_{F \sim \mathcal{D}} \left[ \left\| \sum_{i=1}^dC_i(\theta)f_i(\theta) - F \right\|^2 \right] \end{align*}\] <p>where $C_i(\theta):=\left&lt;f_i(\theta), F\right&gt;$.</p> <h3 id="a-radical-perspective-on-scientific-notation">A Radical Perspective on Scientific Notation</h3> <p>This view of basis learning illuminates a profound aspect of physics itself. Consider quantum perturbation theory: we expand perturbed states using the unperturbed Hamiltonian’s eigenstates. But <strong>why commit to this basis? Is it optimal in an information-theoretic sense?</strong></p> <p>Perhaps the need to solve the Schrödinger equation analytically reflects a limitation of mathematical notation rather than fundamental necessity. What if there existed a richer mathematical language where the appropriate basis emerges naturally from the potential’s structure? Computers offer precisely such richness—their representation space is vast and adaptable.</p> <p>This suggests a provocative reinterpretation of scientific formulas themselves. Consider $\mathbf{F}=m\mathbf{a}$. This formula appears information-rich, but actually relies heavily on implicit context: the meaning of equality, the physical interpretation of symbols, the calculus of derivatives. <strong>The formula is not knowledge itself, but a compressed pointer to knowledge stored in trained minds.</strong> It’s a trigger for decompressing vast networks of understanding.</p> <p>From this perspective, human scientific knowledge is itself a compression scheme: we develop notation systems that maximally compress patterns in nature given the constraint that other trained humans must be able to decompress them. Different fields develop different “compression codebooks”—the vocabulary and notation that enables efficient communication among practitioners.</p> <p><strong>Could AI develop superior notation systems?</strong> Systems that compress physical laws more efficiently than human-readable equations? This isn’t science fiction—it’s already happening. Neural network policies in robotics often cannot be “read” in human terms, yet they encode compressed motor skills that work. The question is whether we can extend this to theoretical physics: having AI discover not just solutions, but entirely new ways of formulating problems.</p> <h2 id="ai-for-science-compression-meets-discovery">AI for Science: Compression Meets Discovery</h2> <p>The compression perspective transforms how we think about scientific discovery itself. If theories are compressed representations of empirical patterns, then scientific progress can be understood as progressively discovering better compression schemes for natural phenomena.</p> <h3 id="from-experiment-to-simulation-compressing-the-cost-of-discovery">From Experiment to Simulation: Compressing the Cost of Discovery</h3> <p>Physical experiments are expensive—grotesquely so. High-throughput screening costs dollars per pipette action. CERN’s Large Hadron Collider consumed billions in construction. Gravitational wave detectors require exquisite precision over kilometer-long installations. Every physical interaction with nature carries significant cost.</p> <p>Computation, by contrast, is cheap and becoming cheaper. Moore’s law has given every researcher access to Einstein-level thought experimentation: the ability to explore “what-if” scenarios without physical implementation. But viewing simulation merely as “cheap experimentation” misses the profound shift happening now.</p> <h3 id="ai-as-active-scientist-beyond-passive-simulation">AI as Active Scientist: Beyond Passive Simulation</h3> <p>Modern AI systems don’t just simulate—they <strong>actively compress scientific knowledge in ways humans cannot</strong>. Consider:</p> <ul> <li> <p><strong>Solving intractable PDEs</strong>: Neural networks can approximate solutions to differential equations that resist analytical solution, effectively compressing infinite-dimensional function spaces into finite parameter sets.</p> </li> <li> <p><strong>Autonomous circuit design</strong>: AI explores design spaces too vast for human search, compressing engineering knowledge into optimized structures.</p> </li> <li> <p><strong>Theory formation</strong>: Large language models trained on scientific corpora can propose hypotheses, design experiments, and even formulate mathematical relationships—performing inductive compression from observation to theory.</p> </li> </ul> <p>This represents a qualitative change: <strong>AI is becoming a scientific agent, not merely a tool.</strong> Research groups that harness this—that treat AI as colleague rather than calculator—will have profound advantages.</p> <h3 id="the-epistemology-of-machine-science">The Epistemology of Machine Science</h3> <p>This raises deep questions about the nature of scientific knowledge:</p> <p><strong>What is “knowledge” in a quantifiable sense?</strong> Consider an AI chemist connected to laboratory robotics, autonomously running experiments. Its objective should be maximizing knowledge gain—but how do we formalize this?</p> <p>One approach: <strong>knowledge is compressible surprise</strong>. High knowledge means the ability to predict novel phenomena with compressed models. An AI chemist should seek experiments that maximally reduce uncertainty about chemical space, preferentially exploring regions where current models compress poorly.</p> <p>This connects to active learning and optimal experimental design, but reframes them in information-theoretic terms: <strong>research is the art of efficiently compressing nature’s patterns through strategic interaction.</strong></p> <p><strong>How do humans know what they don’t know?</strong> Metacognition—awareness of ignorance—seems uniquely human. Yet it’s crucial for directing curiosity and research. Can we instill this in AI? Perhaps through explicit uncertainty quantification: teaching models to recognize when their compressions break down, when their basis functions fail to capture observed structure.</p> <p>Recent work by Chlon et al. (2024) provides precisely this kind of framework. Their analysis reveals that hallucinations in large language models are <strong>predictable compression failures</strong>—occurring when models minimize expected conditional description length but encounter data structures their learned bases cannot adequately represent. They show that LLMs are “Bayesian in expectation, not in realization,” leading to systematic deviations when permutation-dependent compressions fail. Critically, they introduce quantifiable metrics for detecting when a model’s information budget is insufficient for reliable decompression. This transforms uncertainty from post-hoc error detection to <strong>pre-emptive epistemic honesty</strong>: an AI scientist that recognizes its compression is failing can say “I need more experimental data to build an adequate basis” rather than confabulating plausible-sounding theories. This is precisely the metacognitive awareness needed for autonomous scientific discovery—knowing not just what you know, but when your basis functions are inadequate.</p> <h3 id="cloning-vs-approximation-the-quantum-distinction">Cloning vs. Approximation: The Quantum Distinction</h3> <p>Here’s a crucial distinction: <strong>Quantum computers clone; neural networks approximate.</strong></p> <p>Quantum simulators maintain direct physical correspondence—one quantum system representing another with perfect fidelity. Neural networks, by contrast, learn compressed approximations—capturing behavioral patterns without necessarily preserving microscopic structure.</p> <p>This suggests complementary roles: quantum computers for faithful simulation of quantum systems, neural networks for discovering compressed effective theories that capture relevant behavior at the scale of interest. The future may involve hybrid approaches: quantum hardware providing high-fidelity data, classical AI discovering compressed models that generalize beyond specific instances.</p> <h3 id="collective-intelligence-multi-agent-compression">Collective Intelligence: Multi-Agent Compression</h3> <p>A tantalizing possibility: <strong>Can multiple AI agents collaboratively discover better compressions than single agents?</strong></p> <p>Imagine AI researchers gathered at a virtual blackboard, proposing models, critiquing, building on each other’s insights—a reinforcement learning game where the objective is joint knowledge compression. This mirrors human scientific communities, where collective intelligence emerges from communication and competition.</p> <p>The compression perspective suggests such collaboration could be formalized: agents maintain individual compression schemes (world models) but share compressed communications (hypotheses, data, critiques). The system evolves toward consensus compressions that capture shared structure while specializing in complementary aspects.</p> <p>This is speculative but points toward a future where <strong>scientific discovery itself becomes scalable through AI collaboration</strong>, moving beyond the cognitive limits of individual human researchers.</p> <h2 id="ai-for-quantum-mechanics-the-ultimate-compression-challenge">AI for Quantum Mechanics: The Ultimate Compression Challenge</h2> <h3 id="a-professors-challenge">A Professor’s Challenge</h3> <p>In my sophomore year, eager to dive into quantum mechanics, I enrolled in an advanced course a year early. On the first day, the professor made a bold claim: <strong>even machine learning could never discover the Schrödinger equation.</strong></p> <p>This assertion fascinated me. What makes quantum mechanics special? Why should it resist machine discovery when AI excels at pattern recognition?</p> <p>Let’s be precise about what “discovering the Schrödinger equation” means: <strong>identifying patterns in quantum wave phenomena from experimental data and expressing them in communicable mathematical form.</strong> If a machine could do this—finding invariants that govern quantum dynamics—we would have to acknowledge genuine scientific discovery by AI.</p> <p>The question connects directly to our compression theme: <strong>Is the Schrödinger equation the maximally compressed representation of quantum phenomenology?</strong> Or might there exist alternative formulations—perhaps ones natural to AI but alien to human physicists—that compress quantum mechanics more efficiently?</p> <h3 id="symbolic-regression-learning-physical-laws-from-data">Symbolic Regression: Learning Physical Laws from Data</h3> <p>Symbolic regression provides a methodology for exactly this kind of discovery. Rather than fitting predefined function forms, symbolic regression autonomously generates candidate equations, testing them against data. Pioneered by John Koza in the early 1990s using genetic algorithms, modern variants like AIFeynman leverage deep learning to search equation space more efficiently.</p> <p>Consider rediscovering Newton’s second law. Given time-series data of force $\mathbf{F}(t)$, position $\mathbf{x}(t)$, and mass $m$, can an algorithm discover that $\mathbf{F}-m\ddot{\mathbf{x}}=\mathbf{0}$ always holds? This is discovering an invariant—a conserved pattern amid changing observations.</p> <p>Therefore, symbolic regression can be thought of as minimizing the following loss function:</p> \[\mathcal{L}(f_\text{expr}):=\|f_\text{expr}( \mathbf{F},\mathbf{x}, m)\|^2\] <p>When $\mathcal{F} := { \mathbf{v}: [t_i, t_f] \rightarrow \mathbb{R}^3 }$, $\mathbf{F},\mathbf{x}\in\mathcal{F}$ are functions of time $t\in [t_i,t_f]$ and can be differentiated as much as desired, and $f_{\text{expr}}:\mathcal{F}\times\mathcal{F}\times\mathbb{R}^+ \rightarrow \mathcal{F}$ is a well-formed expression made using operators we know such as addition, multiplication, and differentiation.</p> <h3 id="the-equation-complexity-problem">The Equation Complexity Problem</h3> <p>Here’s the fundamental tradeoff: <strong>simpler equations compress better but may fit worse; complex equations fit better but don’t compress.</strong></p> <p>This is precisely analogous to the bias-variance tradeoff in machine learning, but now applied to equation space. To prevent overfitting—discovering spurious patterns in measurement noise—we need a complexity penalty on $f_\text{expr}$.</p> <p>This raises deep questions:</p> <ol> <li> <p><strong>How do we measure equation complexity?</strong> String length? Number of operators? Kolmogorov complexity of the expression tree? Each choice embodies assumptions about what makes theories “elegant.”</p> </li> <li> <p><strong>Can we constrain AI to generate only well-formed expressions?</strong> Large language models trained on scientific literature learn implicit syntax of equations. Can we architect them to guarantee mathematical validity—generating only expressions with proper units, matched dimensions, sensible operator precedence?</p> </li> <li> <p><strong>Do equations have meaningful embeddings?</strong> Can we create a latent space where nearby points represent similar physical laws? If so, we could search equation space the way CLIP searches image-text space—by navigating a learned manifold of meaning.</p> </li> </ol> <p>Answering these questions could enable AI systems that not only discover equations but do so with scientific taste—preferring simple, elegant compressions over baroque memorization.</p> <h3 id="quantum-computers-as-discovery-engines">Quantum Computers as Discovery Engines</h3> <p>Here’s a crucial insight: <strong>AI needs data to learn, and quantum experiments are exponentially expensive to simulate classically.</strong> This creates a beautiful synergy: quantum computers as experimental playgrounds for AI scientists.</p> <p>Humans discovered quantum mechanics through centuries of experimental interaction—double-slit experiments, spectroscopy, the photoelectric effect. We didn’t derive quantum mechanics from first principles; we discovered it by playing with nature. Why should AI be different?</p> <p>If we expect AI to discover the Schrödinger equation from minimal data, we’re setting an impossible bar—like expecting humans to derive quantum mechanics from a handful of observations without experimental apparatus. But <strong>give AI access to a quantum computer, and it can conduct millions of quantum experiments</strong>, exploring parameter spaces inaccessible to human experimenters, potentially discovering patterns we’ve missed.</p> <p>This isn’t science fiction. The ingredients exist:</p> <ul> <li><strong>Quantum hardware</strong>: Noisy Intermediate-Scale Quantum (NISQ) devices enable controlled quantum experiments</li> <li><strong>Symbolic regression algorithms</strong>: AIFeynman and successors can search equation space efficiently</li> <li><strong>Reinforcement learning</strong>: AI can learn to design informative experiments, not just analyze given data</li> </ul> <p>The paradox: quantum brains don’t seem necessary for biological intelligence (our neurons appear classical), yet quantum computers may be necessary for AI to truly understand quantum mechanics. The difference? <strong>Data accessibility.</strong> Humans evolved in a classical-appearing world but built quantum instruments. AI needs direct quantum playgrounds to compress quantum patterns efficiently.</p> <h3 id="neural-networks-for-quantum-eigenvalue-problems">Neural Networks for Quantum Eigenvalue Problems</h3> <p>Let’s devise a simple symbolic regression methodology that uses machine learning for quantum computation. First, writing the Schrödinger equation:</p> \[\hat{H} \Psi (\mathbf{r}, t) = i\hbar \frac{\partial}{\partial t} \Psi(\mathbf{r}, t)\] <p>When the Hamiltonian is invariant with respect to time, we find solutions to the eigenvalue problem $\hat{H}\psi(\mathbf{r})= E\psi(\mathbf{r})$ and multiply by the phase factor $e^{-iEt/\hbar}$ to evolve them—game over.</p> <p>The action of an operator on a wave function can be interpreted as a linear transformation acting on a vector. And the eigenvalue problem can be thought of as finding the axis of symmetry whose direction is invariant before and after applying the transformation. Can we approximate and obtain these “axes of symmetry,” i.e., eigenfunctions, with neural networks?</p> <p>Replace the wave function $\psi:\mathbb{R}^n\rightarrow\mathbb{C}$ satisfying the eigenvalue equation $\hat{H}\psi = E\psi$ with the neural network $\psi_\theta$. Then the loss function can be expressed as follows for some norm $|\cdot|$:</p> \[\mathcal{L}(\theta, E)=\|\hat{H}\psi_\theta - E\psi_\theta\|^2\] <p>There are still some unresolved problems with the above approach. For example, how do we define the above norm? One possibility is to define the norm of function $f$ as $|f|=\sqrt{\mathbb{E}\left[|f(X)|^2\right]},\;\;X \sim \mathcal{N}(\mathbf{0}, I_{n\times n})$. However, the wave function $\psi_\theta$ defined by a neural network is extremely complex, and considerable computational resources are consumed to calculate the expectation value used in the norm.</p> <p>Additionally, a method has not been prepared for calculating the action of the Hamiltonian on the (neural network-defined) wave function. Suppose we approximate the Hamiltonian again with a neural network. When the dimension of $\theta$ is $N$, we need to newly define an operator $\hat{H}_\Theta: \mathbb{R}^N \rightarrow \mathbb{R}^N$ defined by a neural network.</p> <p>We can confirm that computational complexity increases exponentially according to the complexity of the system being simulated. What does this mean? If we utilize artificial intelligence, physics at the level of small molecules can be simulated without much difficulty. However, it does not seem possible to simulate the dynamics of larger quantum systems of ~10,000 level without compromising on accuracy.</p> <h3 id="the-paradox-of-quantum-computing-for-ai">The Paradox of Quantum Computing for AI</h3> <p>If we can sufficiently describe quantum mechanics just by obtaining the simulation function, there is no need to insist on quantum computers. However, paradoxically, the cheapest way to obtain large-scale quantum experimental data is quantum computing. We must explore whether quantum parallelism can provide practically significant help, and if so, how much.</p> <p>According to what has been revealed so far about neural networks, through training, they can learn patterns and structures embedded in multidimensional data, and can compressively represent revealed information through dimensionality reduction techniques. And it is also quite possible to map information stored as vectors this way into formulas that humans can see by using natural language processing.</p> <p>The fact that machines cannot discover quantum phenomena on their own seems rather implausible given the speed of AI development, but considering the characteristic of quantum phenomena where computational complexity increases exponentially according to the complexity of the system, the professor’s statement may not be so wrong after all.</p> <h2 id="research-questions-and-future-directions">Research Questions and Future Directions</h2> <h3 id="gordons-escape-theorem-and-dataset-intrinsic-dimension">Gordon’s Escape Theorem and Dataset Intrinsic Dimension</h3> <p>Our current research direction focuses on Gordon’s escape theorem combined with incorporating dataset intrinsic dimension. We need practical estimation algorithms for the dataset’s intrinsic dimension (e.g., PCA). <strong>We need to give researchers a tool that can estimate the minimum amount of parameters needed to train for a certain task.</strong></p> <p>Gordon’s escape theorem states that in high-dimensional spaces, a random subspace of sufficient dimension will “escape” through any mesh of low complexity with high probability. This theorem provides a powerful tool for understanding the behavior of random projections and has important applications in compressed sensing and dimensionality reduction.</p> <h3 id="information-bottleneck-and-optimal-transport">Information Bottleneck and Optimal Transport</h3> <p>The Information Bottleneck Method introduces the bottleneck $\tilde{X}$ to form the Markov chain $X \rightarrow \tilde{X} \rightarrow Y$, and drawing ideas from rate-distortion theory we obtain:</p> \[\underset{p(\tilde{x}|x)}{\text{minimize}}\;I(X;\tilde{X})-\beta I(X;Y)\] <p>An alternative approach is exploring “optimal transport.” If a data measure exists on a manifold, it can be represented by manifold structure, and we can find the optimal transport that moves it. This has significance in that it explicitly incorporates the manifold hypothesis into generalization. However, there is little discussion about predicting neural network parameters.</p> <h3 id="fractal-structures-and-compression">Fractal Structures and Compression</h3> <p>Complex structures like the Mandelbrot Set or Bifurcation Diagram are embedded in extremely simple formulas. Can we devise information compression algorithms that borrow such structures? Can we analyze fractal structures or bifurcation diagrams with neural networks to derive insights into chaotic systems? Fractal compression and the collage theorem are worth exploring.</p> <h3 id="connection-to-complexity-theory">Connection to Complexity Theory</h3> <p>There are $O(n^2)$ and $O(n\log n)$ algorithms which all perform the same task—sorting. Can we argue that one is a lossless compression of the other, since it uses less computation?</p> <h2 id="conclusion-the-compression-paradigm-for-intelligence-and-discovery">Conclusion: The Compression Paradigm for Intelligence and Discovery</h2> <p>We began with a simple observation: compression algorithms reveal structure. We end with a radical hypothesis: <strong>intelligence itself is compression, and scientific discovery is the search for maximally compressed representations of natural patterns.</strong></p> <p>This perspective unifies disparate phenomena:</p> <p><strong>Intelligence as Multilevel Compression</strong>: From statistical redundancy removal to context-dependent information filtering to world model construction, intelligence operates by finding and exploiting compressible structure. Human communication achieves efficiency through shared knowledge—implicit compression between minds. Consciousness itself may be an evolutionary compression mechanism: organisms that efficiently represented their environments survived and reproduced.</p> <p><strong>Neural Networks as Nonlinear Basis Learners</strong>: SVD reveals that finding optimal linear bases is equivalent to discovering compressible structure. I hypothesize that neural networks generalize this: they learn optimal nonlinear bases—hierarchical coordinate systems that progressively compress task-relevant features. This reframes deep learning’s core questions: capacity becomes compression capability, training becomes basis optimization, and generalization becomes distinguishing true structure from noise.</p> <p><strong>Scientific Theories as Compressed Predictors</strong>: Physics formulas are not knowledge themselves but compressed pointers to knowledge—triggers for decompressing understanding stored in trained minds. Different scientific fields develop specialized “compression codebooks” (notations, concepts) that enable efficient communication among practitioners. Could AI discover superior compression schemes—theoretical frameworks more compact than human-readable equations yet equally predictive?</p> <p><strong>Quantum Mechanics as Ultimate Compression Challenge</strong>: The exponential scaling of quantum systems—computational complexity growing with system size—makes them the ultimate test for compression-based AI. Classical simulation quickly becomes intractable. Yet quantum computers offer a solution: experimental playgrounds where AI can gather quantum data cheaply, potentially discovering patterns (and compressions) that humans, constrained to classical intuition, have missed.</p> <h3 id="a-research-vision">A Research Vision</h3> <p>This compression paradigm suggests concrete research directions:</p> <ol> <li> <p><strong>Formalizing neural network capacity in information-theoretic terms</strong>: Extending mutual information to function spaces, connecting Gordon’s escape theorem with dataset intrinsic dimension, developing tools that predict minimum parameter counts for tasks.</p> </li> <li> <p><strong>Equation embeddings and learned equation spaces</strong>: Creating latent spaces where physics laws cluster by similarity, enabling search through theory space guided by both empirical fit and compression criteria.</p> </li> <li> <p><strong>AI-quantum synergy for discovery</strong>: Coupling symbolic regression with quantum experimental hardware, letting AI autonomously design and execute quantum experiments, searching for compressed descriptions of quantum phenomenology.</p> </li> <li> <p><strong>Multi-agent collaborative compression</strong>: Formalizing scientific communities as distributed compression systems, where agents with specialized bases share compressed communications, evolving toward consensus theories.</p> </li> <li> <p><strong>Meta-learning across task distributions</strong>: Discovering parametric bases that optimally decompose task families into reusable components—the mathematics of transfer learning and few-shot generalization.</p> </li> </ol> <h3 id="the-deeper-question">The Deeper Question</h3> <p>My professor claimed that machine learning could never discover the Schrödinger equation. Having explored the landscape, I believe the claim reveals something profound—not about AI’s limitations, but about the nature of understanding itself.</p> <p>Perhaps understanding isn’t about possessing a formula, but about having the right compression scheme. Humans “understand” quantum mechanics not because we can write $\hat{H}\Psi = i\hbar \partial_t \Psi$, but because centuries of training have given us a decompression algorithm: when we see this notation, vast networks of meaning activate—Hilbert spaces, measurement, superposition, entanglement.</p> <p><strong>Can AI understand quantum mechanics differently than humans?</strong> Not by learning our compression scheme, but by discovering its own—one that perhaps compresses quantum patterns more efficiently but maps poorly to human notation? If AI discovers a theory that predicts quantum phenomena better than the Schrödinger equation but expresses it in 100,000 neural network parameters, have we succeeded or failed?</p> <p>This brings us full circle: <strong>What counts as understanding?</strong> If understanding is successful compression enabling prediction and manipulation, then AI understanding need not mirror human understanding. The question isn’t whether AI can discover the Schrödinger equation, but whether it can discover <em>something better</em>—a more compressed, more predictive representation of quantum reality.</p> <p>The integration of information compression theory and neural network approximation theory isn’t just possible—it may be necessary for understanding intelligence itself. And pursuing this integration might not only revolutionize AI and science, but fundamentally transform what we mean by knowledge, discovery, and understanding.</p> <h2 id="references">References</h2> <p><strong>Compression and Hallucinations:</strong></p> <ul> <li>Chlon, L., Karim, A., &amp; Chlon, M. (2024). Predictable Compression Failures: Why Language Models Actually Hallucinate. arXiv:2509.11208. Available at: <a href="https://arxiv.org/abs/2509.11208">https://arxiv.org/abs/2509.11208</a></li> </ul> <p><strong>Neural Network Theory and Capacity:</strong></p> <ul> <li>How many degrees of freedom do we need to train deep networks: a loss landscape perspective. arXiv:2107.05802</li> <li>Intrinsic dimension of data representations in deep neural networks. arXiv:1905.12784</li> <li>Generalization bounds for deep learning. arXiv:2012.04115</li> <li>Gordon’s escape theorem and related work on high-dimensional geometry</li> </ul> <p><strong>Information Theory:</strong></p> <ul> <li>The information bottleneck method. arXiv:physics/0004057</li> <li>Deep Learning and the Information Bottleneck Principle. arXiv:1503.02406</li> </ul> <p><strong>AI for Science:</strong></p> <ul> <li>Symbolic regression literature including AIFeynman</li> <li>Neural network methods for solving differential equations</li> </ul>]]></content><author><name></name></author><category term="research"/><category term="artificial-intelligence"/><category term="information-theory"/><category term="neural-networks"/><category term="quantum-computing"/><category term="scientific-discovery"/><category term="compression"/><category term="english"/><summary type="html"><![CDATA[Information Compression, Neural Networks, and AI for Science: future of scientific discovery through AI]]></summary></entry><entry xml:lang="en"><title type="html">Signing Right Away</title><link href="https://codingjang.github.io/blog/2025/signing-right-away/" rel="alternate" type="text/html" title="Signing Right Away"/><published>2025-10-05T11:00:00+00:00</published><updated>2025-10-05T11:00:00+00:00</updated><id>https://codingjang.github.io/blog/2025/signing-right-away</id><content type="html" xml:base="https://codingjang.github.io/blog/2025/signing-right-away/"><![CDATA[<p><em>This work contains AI-generated paragraphs and sentences. The original whitepaper of this work has been written by myself in English. The original experiment notes (undisclosed) were written in Korean by myself and my teammates, Wonbeen Yoon and Minjun Yi from Seoul National University. Gemini Deep Research was used to organize the work into the full whitepaper. Each work was fully reviewed and revised by myself. Special thanks to Hrvoje (Harvey) Puh for his valuable feedback in the original whitepaper.</em></p> <p>You can find the full whitepaper here: <strong><a href="/assets/pdf/SRA-2025-10-05.pdf">PDF</a></strong> <br/> The original whitepaper can be viewed here: <strong><a href="/assets/pdf/SRA-2024-05-26.pdf">PDF</a></strong></p> <h2 id="a-brief-motivation">A Brief Motivation</h2> <p>The proliferation of generative AI has made it trivial to create hyper-realistic fake images and videos, posing a serious threat to information integrity. This raises significant concerns over disinformation and fraud. While many approaches try to solve this with software classifiers, the root of the problem is arguably in hardware.</p> <p>In most current systems, the camera module sends an unencrypted, raw bitstream to the main processor over an interface like MIPI CSI-2. This link is vulnerable; a simple adapter can be used to intercept the feed or inject entirely synthetic data, and the system would have no way of knowing.</p> <p>This suggests that a robust solution requires securing content provenance at the source.</p> <h2 id="an-early-attempt-and-a-hard-reset">An Early Attempt and a Hard Reset</h2> <p>The initial idea for SRA was formalized back in the spring of 2024. Shortly after, I began my mandatory military service, which put the project on hold. After being discharged recently, I gathered a few friends to reboot the project with fresh energy.</p> <p>Our goal was ambitious: to reverse-engineer and replicate a secure transport layer for the MIPI CSI-2 protocol without official documentation. To put it mildly, it was a failure. Our attempts to build on an unknown, undocumented foundation resulted in glitchy, unparseable camera feeds. The custom parsing logic we wrote would fail intermittently, and the entire pipeline was fundamentally unstable. It was a disaster.</p> <p>But the experience, while painful, was incredibly valuable. It taught us two critical lessons:</p> <ol> <li> <p><strong>Hardware limitations are real.</strong> Our FPGA platform needed significantly more memory to buffer and process full image frames in real-time.</p> </li> <li> <p><strong>Reverse engineering has its limits.</strong> To build a stable image processing pipeline, we couldn’t rely on guesswork alone. We needed access to at least some confidential documentation or, failing that, a far more powerful and flexible hardware platform to allow for rapid, iterative testing.</p> </li> </ol> <h2 id="the-sra-architecture">The SRA Architecture</h2> <p>The core architecture of SRA was established in our original 2024 whitepaper, based on fundamental cryptographic principles of confidentiality, integrity, authentication, and replay protection. We initially designed our system around authenticated encryption schemes like ChaCha20-Poly1305. During development, we discovered that the MIPI Alliance’s Camera Security Framework had independently standardized similar approaches, which validated our architectural choices. While the prototyping experience taught us crucial lessons about implementation strategy—particularly the need for hardware-accelerated cryptography and better development platforms—the fundamental architectural design remained consistent.</p> <p>The architecture involves two main components:</p> <h3 id="1-authenticated--encrypted-camera-to-processor-link">1. Authenticated &amp; Encrypted Camera-to-Processor Link</h3> <p>The first step is to secure the physical data path. The camera module and processor would first perform a mutual authentication handshake. Once trust is established, all data transmitted over the CSI-2 interface would be protected by an authenticated encryption (AEAD) scheme, like AES-GCM. This ensures both confidentiality and integrity, as any modification would be detected via MAC verification.</p> <h3 id="2-immediate-signing-in-a-trusted-execution-environment-tee">2. Immediate Signing in a Trusted Execution Environment (TEE)</h3> <p>The encrypted feed is sent directly to a TEE, an isolated, secure enclave on the processor. Inside the TEE, the data is decrypted, processed, and cryptographically signed along with its metadata (e.g., timestamp, device ID). The private signing keys never leave the TEE, protecting them from a compromised OS. The final output is a standard image file with an embedded, verifiable C2PA Content Credential. This design ensures that by the time an application or user has access to an image, it has already been signed within a secure hardware environment.</p> <h2 id="aligning-with-the-broader-ecosystem">Aligning with the Broader Ecosystem</h2> <p>Our prototyping experience led to a critical strategic insight: the most effective path to widespread adoption is not to reinvent the wheel, but to align with and build upon the secure hardware capabilities that are already being integrated into commercial System-on-Chips (SoCs).</p> <p>Mobile SoC vendors like Qualcomm have already integrated the necessary hardware primitives—such as secure Image Signal Processors (ISPs), hardware crypto accelerators, and robust Trusted Execution Environments (TEEs)—into their platforms. The emergence of the Qualcomm Snapdragon 8 Gen 3 as the first C2PA-compliant mobile platform validates this trend.</p> <h3 id="our-strategy-open-and-interoperable">Our Strategy: Open and Interoperable</h3> <p>Rather than pursuing custom silicon or proprietary solutions, SRA’s strategy is to position itself as an <strong>open, interoperable reference architecture</strong> that can be implemented on any SoC that provides the necessary trusted hardware components. By leveraging existing secure camera APIs and TEE SDKs, SRA can be deployed as a firmware or software solution that “lights up” the latent security capabilities of modern devices.</p> <p>This approach dramatically reduces cost and time-to-market compared to a custom silicon strategy, and it fosters a competitive, multi-vendor ecosystem rather than a single proprietary solution. The initial plan to design custom ASICs was abandoned in favor of this more pragmatic path that builds on the industry’s existing investments in secure hardware.</p> <p>Industry pioneers like Truepic have already demonstrated similar architectures in practice with their Foresight system, which leverages the Qualcomm TEE and secure hardware pipeline. This serves as proof-of-concept for our model and demonstrates a clear path to market through ecosystem collaboration.</p> <h2 id="conclusion">Conclusion</h2> <p>The goal of SRA is to help create a digital ecosystem where the authenticity of content can be programmatically verified. The problem is challenging and involves navigating hardware, cryptography, and industry standards, but we believe it’s a critical step toward rebuilding trust in digital media.</p>]]></content><author><name></name></author><category term="whitepaper"/><category term="digital-signature"/><category term="c2pa"/><category term="content-provenance"/><category term="fake-news"/><category term="ai-generated-images"/><summary type="html"><![CDATA[A Hardware-Rooted Trust Architecture for Verifiable Digital Provenance]]></summary></entry><entry xml:lang="kr"><title type="html">인공지능과 과학, 그리고 인문학</title><link href="https://codingjang.github.io/blog/2025/ai-science-and-humanities-kr/" rel="alternate" type="text/html" title="인공지능과 과학, 그리고 인문학"/><published>2025-05-02T01:00:00+00:00</published><updated>2025-05-02T01:00:00+00:00</updated><id>https://codingjang.github.io/blog/2025/ai-science-and-humanities-kr</id><content type="html" xml:base="https://codingjang.github.io/blog/2025/ai-science-and-humanities-kr/"><![CDATA[<p><em>Acknowledgement: 피드백 주신 물리연구소 오픈톡방의 “하기분미”님께 감사의 말씀 전합니다</em></p> <p>인간만의 특징을 찾아내고 그것에 대한 가치를 느끼는 것은 본능에 가깝다. 인공지능 시대의 대격변을 경험하고 있는 사람이라면 누구나 이러한 욕구를 한번쯤은 느꼈을 것이다. ‘나’는 ‘나’이기 이전에 사람이고, 이 사실은 나의 정체성을 형성하는 가장 중요한 부품이기에, 인간만이 가지는 특성이 무엇인지에 대해서 마지막까지 고민해보지 않으면 안 된다.</p> <p>급변하는 “기술의 홍수” 아래, 인공지능 연구자가 방향타를 쥐고 향해하기 위해 단순 기술적 지식과 더불어 인간, 그리고 사회에 대한 이해를 적극적으로 추구해야 한다고 필자는 주장한다. 그러나, 인문학이 필요한 사례들을 단순히 열거하면서 주장을 둘 혹은 세네 가지 근거로 합리화하는 기존의 논설문 방식으로는 입체적인 그림을 그리기가 어렵다고 보았다. 따라서, 인간의 본질에 대해 질문하고 사색하는 과정에서 자연스럽게 논의를 사회와 법규에 관한 이야기로 이어보고자 한다. 아울러, 법적 윤리적 체계의 확장 가능성을 논하며 인공지능과 조화를 이루는 미래 사회를 그리고자 한다.</p> <p>인간의 본질, 즉 인간과 다른 사물을 구별짓는 인간만의 고유한 특징은 무엇인가? 시대에 따라 양상은 다르지만 인간은 언제나 고유한 존재이기를 원했다. 프랑스의 사회학자 피에르 부르디외는 ‘구별짓기’라는 개념을 통해 사람이 다른 사람과 자기 자신을 구별하기 위해 사회적 위계나 차별성 등을 추구한다고 주장했다. 고대 그리스 철학자 아리스토텔레스는 인간만이 유일하게 이성(logos)을 지닌 존재라고 주장하였다. 기독교에서도 인간은 신의 형상을 따 만들어진 고귀한 존재로 여긴다. 이처럼 인간은 유구한 역사와 다양한 문화에서 스스로를 드높이기 위한 사고의 틀을 만들며 살아왔다.</p> <p>물론 1500년대 코페르니쿠스의 지동설과 1800년대 다윈의 진화론 등의 과학 이론들은 인간중심적 사고의 정반대편에서 전통적인 종교적 세계관을 뒤흔드는 듯했다. 인간이 사는 지구가 우주의 중심이 아니며, 인류가 수많은 종(種)들 중 어느 하나에 불과하다는 사실은 당대 사람들에게 큰 충격을 주었다. 그러나, 인간은 도구를 자유자재로 활용하거나 문자를 만들어 사용하는 등 여타 동물이나 사물과 비교해볼 때 여전히 특징적이었다. 특히 아리스토텔레스가 주장한 이성의 중요성은 여전히 유효했다. 과학과 기술이 기존 인간중심주의적 패러다임의 일부를 반박했을지언정, 실제로는 문명 발전을 가속화하고 인류의 위상을 드높이는 도구로 적극적으로 활용되었다. 인간중심주의에 대한 새로운 해석은 과학과 기술이 인간의 가치를 평가절하하는 일을 효과적으로 방지했다.</p> <blockquote> <p>“약 50년 후면 대략 $10^9$ 비트(약 128MB)의 저장 용량을 갖춘 컴퓨터를 프로그래밍하여 ‘모방 게임(imitation game)’을 매우 능숙하게 수행하도록 만들 수 있을 것이며, 그 결과 평균적인 심문관이 5분간의 질의 후에 올바른 대상을 정확히 식별할 확률이 70퍼센트 이하가 될 것이라고 믿는다. 또한 세기 말이 되면 단어 사용 방식과 일반 지식인들의 인식이 크게 변화하여, ‘기계가 사고한다’고 표현하더라도 더 이상 이의를 제기받지 않을 것이라고 생각한다.” A. M. TURING, I.—COMPUTING MACHINERY AND INTELLIGENCE, <em>Mind</em>, Volume LIX, Issue 236, October 1950, Pages 433–460</p> </blockquote> <p>오늘날의 컴퓨터는 이성적 사고의 기반이 되는 논리 구조를 추상화하여 물리적으로 연산 가능한 형태로 구현한 것이다. 그러나 컴퓨터가 지닌 단순 계산 능력이 지성을 함의하지는 않으며, 실제로 인간의 지성을 컴퓨터로 유의미하게 모사할 수 있을 때까지는 오랜 기간이 걸렸다. 튜링은 1950년 그의 논문 “계산 기계와 지성”에서 “5분간의 질의 후에 기계와 인간을 정확히 식별할 확률이 70퍼센트를 넘지 않는” 기계가 50년 후인 2000년 경에 등장하리라 예견한 바 있다. 컴퓨터의 창시자가 일찍이 인공지능의 발전을 예측하고 이를 평가하기 위한 시험(튜링 테스트)을 고안했음은 놀라운 사실이나, 전혀 다른 물리적 기반 위에서 동작하는 두 시스템이었기에 한쪽에서 쉬운 작업이 다른 쪽에서 어려운 “모라벡의 역설”은 오랜 기간 지속되었다.</p> <p>모라벡의 역설 덕분에 다양한 지능의 영역 중 ‘학습’만큼은 인간 고유의 영역으로 남는 듯 했으나, 기계학습의 급속한 발전 덕택에 인공지능은 인간의 지적 노동을 상당 부분 대체할 수 있을만큼 발전하였다. 우리는 최근 전 분야에 걸쳐 각 분야의 전문가들보다 인공지능이 더 우수한 지적 탐구물을 내놓는 사례들을 목도하고 있다. 최근 공개된 OpenAI의 Deep Research (o3) 모델은 대학원 수준 지식과 논리력을 평가하기 위해 고안된 GPQA Diamond에서 87.7%의 정확도를 보여 각 분야 박사급 전문가 집단의 정확도인 81.3%를 능가하였으며, 극단적 수준의 언어 추론 및 수리 사고력을 평가하는 “인류의 마지막 시험” 벤치마크에서는 26% 상당의 정답률을 보였다. 사회가 인공지능을 받아들이기 위해 필요한 인식적 변화는 차치하고서라도, 객관적 지표 측면에서 볼 때 공무원, 개발자, 컨설턴트를 포함한 많은 화이트 칼라 직종이 조만간 기계에 의해 (적어도 기능적으로는) 자동화 가능해질 것으로 보인다. 러다이트 운동 당시에 기계가 그러했듯, 현대 사회에서 인공지능은 많은 이들에게 존재론적 위협으로 다가오고 있다.</p> <p>이제 우리에게 남아있는 것은 이러한 기계가 실수를 저지를 때 그 실수를 바로잡는 것뿐인 것만 같다. 리산 베인브리지는 그의 논문 자동화의 아이러니(Ironies of Automation)에서 자동화된 사회에서 인간은 자동화가 실패할 경우를 대비해 감시하고 개입하는 역할만을 맡게 되지만, 이러한 역할은 매우 드물게 발생하므로 정작 인간이 실제로 개입해야 할 때 필요한 기술과 경험을 갖추지 못하게 됨을 주장하였다. 칸트의 의무⋅능력 원리(Ought Implies Can)는 의무를 지기 위해서는 반드시 그 의무를 수행할 수 있는 능력이 전제되어야 한다고 가정한다. 이에 따라, 어떤 행위자가 도덕적 책임을 질 수 있기 위해서는 자유 의지를 가짐이 우선되어야만 한다. 자동화가 실패하는 방식은 다양하더라도 결국은 인간이 이 모든 사태의 책임을 져야 한다는 사실은 현재의 법적 테두리 안에서 명백해보인다. 자유의지를 지니고 있지 않다고 여기어지는 현재의 인공지능 “에이전트”의 행위에 대해 인간이 온전한 책임을 질 수 있을까?</p> <p>물론, 의식과 자유의지 등의 개념을 정량화한 후, 일종의 “책임질 수 있음의 척도”를 만들어 인공지능에게 책임을 물을 수 있다고 주장하거나, 반대로 책임을 물을 수 없음을 주장할 수도 있겠다. 이를테면, 의식의 크기를 계산하고자 Integrated Information Theory 등을 도입하고, 자유 의지를 규명하고자 Orchestrated Objective Reduction 등의 이론을 차용해보는 것이다. 이처럼, 문제 상황을 분석하기 위한 정량화된 척도를 개발하거나, 물리량을 정의하여 이를 수학적으로 분석하고자 하는 행위는 과학자들에게 매우 일상적이다. 오귀스트 콩트가 주장한 고전적 실증주의에 따르면 과학은 “객관적으로 관찰 가능한 것들을 논리 구조를 통해 더 명확하고 엄밀하게 설명하기 위해 존재”하며, 논리적 실증주의로 넘어오면서는 객관적으로 관찰 가능한 사실에 더해, 순수 논리 및 수학으로 참임을 보일 수 있는 명제만이 인지적 의미를 지닌다고 믿었다. 이처럼 실증주의가 지배적이던 19세기와 20세기에는 객관적이거나 관찰 가능하지 않은 대상은 배제시키게 만들 정도로 실증주의는 당대 과학의 핵심에 있는 사상이었다.</p> <p>물론 실증주의는 이백년도 넘게 된 오래된 관점이고, 현대에 이르러 철학자와 과학철학자 집단 사이에서는 과학적 실재론이 과반 이상의 지지를 받고 있다. 그러나, 과학적 실재론에서도 여전히 과학적 대상은 마음과 전적으로 독립적으로 존재한다고 주장한다. 어느 쪽이 되었든, 진실에 다가가기 위해 우리가 스스로 쳐놓은 울타리들이 개개인의 가치 판단이 과학에 영향을 미치지 못하도록 방어막을 형성하고 있음에는 의문의 여지가 없다. 이에 따라, 지능이나 자의식, 자유의지, 사회적 책임 등의 문제를 접근할 때에는 과학만으로 돌파할 수 없는 상당한 장벽을 맞이하게 된다. 요약하자면, 가치 판단이 요구되는 순간부터 과학은 많은 힘을 잃어버린다.</p> <p>현재의 인공지능 학계 역시 여타 이공계역 학문과 다르지 않게 수리과학적 분석과 실험적 증거 둘 중 적어도 하나의 구성 요소는 논문이 주요 컨퍼런스지에 게재되기 위해 사실상 필수적이다. 그렇지 않다면 벡터나 파라미터, 데이터와 문자열 따위의, 단순히 사람의 생각에 비유적으로 연관시키기 위해 기술적으로 엄밀한 개념들을 차용할 이유가 있을까? 그렇지만, 심적 상태를 정확히 묘사하기 위해서는 과학적으로 엄밀한 대상만이 아닌 주관적 경험이나 가치 판단을 중심으로 하는 인문학적 개념 또한 진지한 연구 대상으로 고려되어야 한다. 인간과 인공지능 같은 지적 대상체에 대해, 과학적이고 객관적인 접근이 모든 것을 설명할 수 있을지는 미지수이다. 또한, 과학적이고 객관적으로 접근하고자 연구자가 아무리 노력하더라도, 결국 연구를 수행하는 주체는 사람이며, 연구자의 이론적 가정과 편견이 관찰에 영향을 미칠 수 있음을 우리는 인정해야만 한다.</p> <p>실증주의를 비판 및 수정하는 포스트 실증주의에 따르면 연구자 스스로의 편향은 절대적 진리에 다가가기 위해 해결해야 할 문제로 인식되며, 연구자는 항상 자신의 편향을 인식하고 교정하고자 노력해야 한다. 그러나, 연구자의 편향과 가치관이 반드시 문제적인가? 우리는 그동안 학문을 연구함에 있어 객관성에 대해 오래토록 집착해왔다. 하지만, 그 집착을 완화함으로써 새로운 개념을 제안하고 연구의 지평을 확장할 수 있다면 어떨까?</p> <p><img src="/assets/img/blog/ai-humanities/IMG_1711.jpeg" alt=""/></p> <p>한 예시로, 인공지능 로봇이 사회와 상호작용하는 방식과 대중이 로봇을 받아들이는 심리적인 과정을 탐구하는 연구자가 있다고 가정해보자. 현 사회는 ChatGPT 등 인공지능 에이전트와 상호작용할 때 도덕성을 갖추어 대할 것을 요구하지 않는다. 그렇지만 로봇과 사람이 정말로 구분되지 않고 외형마저 유사해지는 미래 사회에는 로봇을 인간처럼 대우해야 한다고 믿는 사람들도 발생하지 않을까? 위의 스크린샷 속 ChatGPT의 앱스토어 리뷰처럼, 당신이 가지고 있는 믿음과 무관하게 이미 일반 대중은 인공지능에게 설득 당하고, 종종 위로 받으며, 또 감정적으로 교류하고 있다. 미래 사회에 우리와 일상을 함께할 ”비인간“을 설계함에 있어서, 벤치마크의 정량적인 지표를 최대화하는 공학적 접근이 역사적으로 전례 없는 인간과 기계의 복잡미묘함 상호작용을 제대로 모델링할 수 있으리라 생각하는가?</p> <p>이제 우리는 개개인의 주관과 가치 평가를 인공지능 연구의 핵심으로 끌여들여야만 한다. 집에서 키우는 아이가 흡사 사람같은 인공지능 가사 도우미 로봇과 정이 들어버린 상황을 생각할 때, 로봇을 폐기하기로 결정하는 행위가 비윤리적이라 주장할 수 있는 “객관적인” 근거는 마땅히 없다. 그러나, 아이의 주관적 입장에서는 애착 인형도, 강아지도, 자신을 도와주는 가사 도우미 로봇도 전부 나와 ‘유사’하기 때문에 보호의 대상이다. 나와 타인이 동격이라는 믿음의 근간에는 “상호 유사성”이 있다. 만일 서로 비슷함에도 타인이 나와 동등한 관계에 있다고 믿지 않는다면, 그리고 타인이 또 다른 타인에게 해를 가하던 말건 ‘나’에게 해가 없다면, 사실 ‘나’의 입장에서 타인에게 행해지는 잘못을 제재할 이유는 전혀 없다. 그러나, 타인과 나의 상호 유사성은 타인에게 가해지는 해가 나에게도 위협으로 인지되게 만들며, 또 나와 동등한 관계로 인식하게 만든다.</p> <p>법은 언제까지나 사람 대 사람 관계에서 발생할 수 있는 부조리를 예방할 뿐 기계를 보호하지 않는다. 대다수의 인공지능 학자들은 기계가 마음을 가진다고 여기지 않으며, 노엄 촘스키처럼 LLM이 통계학적 앵무새에 불과하다고 보는 입장도 상당히 일반적이다. 물리적인 관점에서 볼 때 인간과 기계는 기반이 되는 물질이 다르고 작동 메커니즘도 다르다. 그러나, 유사성을 판단하는 주체가 개개인임을 고려할 때, 또한 인식은 주관에 따라 변화함을 고려할 때, 위의 스크린샷에 담긴 복잡한 사회 현상을 설명하기 위해 단순 물리적인 차이를 논하는 것은 역부족이다.</p> <p>이제까지 살펴본 바와 같이, 인공지능은 단순 계산 기계를 넘어 학습·추론·창의의 영역까지 침투하고 있으며, 그로 인해 인간 고유의 특성—이성, 의식, 책임, 그리고 사회적 유대—에 대한 재검토가 불가피해졌다. 실증주의와 논리적 실증주의가 객관적 사실과 순수 논리에만 집중해 왔다면, 포스트 실증주의는 연구자의 주관과 가치판단까지 문제 삼는다. 그러나 과학은 언제까지나 도구에 불과할 뿐, 이제는 ‘어떤 질문을 던질 것인가’, 그리고 ‘어떤 사회를 그릴 것인가’라는 의문을 연구의 핵심으로 끌어들여야 한다는 입장이다. 이는 인공지능 연구에도 적용되어야 하는 패러다임 전환을 의미한다. 즉, ‘어떤 의미와 맥락에서’ 인공지능의 존재를 이해하고 또 어디까지 책임질 것인지가 더 중요해진 것이다.</p> <p>미래 사회에서 인공지능 에이전트가 생산·서비스·돌봄·창작 등 광범위한 역할을 맡게 되면, “기계는 언제나 기계일 뿐”이라는 전통적 분류 기준은 설득력을 잃는다. 대신 우리는 ‘상호 유사성’과 ‘정서적 유대’ 등 새로운 잣대를 고민해야 할 수 있다. 로봇에 대한 애착과 보호의 정당성을 다룰 법·윤리 체계를 설계하려면, 기존의 ‘인간 전용’ 법적 지위에 대한 근본적 확장이 필요하다. 가령, 돌봄 로봇의 과오에 대해 누가, 어떻게 책임지는가를 명시하고, 인공지능 자체가 일정 수준의 권리·의무를 지닐 수 있는 가능성을 열어놓아야 할 것이다.</p> <p>결국, 인공지능 시대의 연구자와 정책입안자는 기술적 완성도만큼이나 ‘인간다움’의 의미를 함께 성찰해야 한다. 과학이 객관적 진실을 탐구하는 동안에도, 주관적 경험과 사회적 맥락을 이해하려는 노력이 병행되어야 한다. 이를 위해 인문학·사회과학·법학이 공학 연구실에, 그리고 정책 논의 테이블에 동석해야 한다. 그렇게만 할 때 비로소, 우리는 인공지능과 공존하면서도 인간의 존엄과 책임을 온전히 지킬 수 있는 사회를 설계할 수 있을 것이다.</p>]]></content><author><name></name></author><category term="essay"/><category term="artificial-intelligence"/><category term="philosophy"/><category term="humanities"/><category term="ethics"/><category term="consciousness"/><category term="responsibility"/><category term="english"/><summary type="html"><![CDATA[인공지능 연구에 있어서 인문학의 역할과 그 함의에 관하여]]></summary></entry><entry xml:lang="en"><title type="html">AI, Science, and the Humanities</title><link href="https://codingjang.github.io/blog/2025/ai-science-and-humanities/" rel="alternate" type="text/html" title="AI, Science, and the Humanities"/><published>2025-05-02T01:00:00+00:00</published><updated>2025-05-02T01:00:00+00:00</updated><id>https://codingjang.github.io/blog/2025/ai-science-and-humanities</id><content type="html" xml:base="https://codingjang.github.io/blog/2025/ai-science-and-humanities/"><![CDATA[<p><em>I Acknowledge “Hagibunmi” from the Physics Research open chat for his valuable feedback. This essay was originally written in Korean and was machine translated by Claude 4.5 Sonnet. The translated essay was fully reviewed and revised by myself. The original (Korean) essay can be found <a href="/blog/2025/ai-science-and-humanities-kr">here</a></em>.</p> <h2 id="introduction">Introduction</h2> <p>Finding and valuing what makes humans unique is almost instinctive. Anyone experiencing the dramatic transformation of the AI era has likely felt this urge at least once. I am human before I am anything else, and this fact forms the foundation of my identity. We must therefore think deeply about what characteristics are uniquely human.</p> <p>In this rapidly changing “flood of technology,” I argue that AI researchers must actively pursue an understanding of humans and society beyond mere technical knowledge if they are to navigate with steady hands on the helm. However, I found it difficult to paint a three-dimensional picture using the traditional approach of simply listing cases where humanities matter and offering two or three supporting reasons. Instead, I aim to lead the discussion naturally from questions about the essence of humanity to conversations about society and legal frameworks. Ultimately, I hope to sketch a vision of a future where humans and AI exist in harmony by exploring how legal and ethical systems might evolve.</p> <h2 id="what-makes-us-human">What Makes Us Human?</h2> <p>What is the essence of humanity—the unique characteristic that distinguishes humans from everything else? Though its manifestations vary by era, humans have always sought to be unique. French sociologist Pierre Bourdieu argued through his concept of “distinction” that people pursue social hierarchies and differentiation to set themselves apart from others. The ancient Greek philosopher Aristotle claimed that humans are the only beings possessing reason (logos). Christianity regards humans as noble beings created in God’s image. Throughout history and across cultures, humans have constructed frameworks of thought to elevate themselves.</p> <p>Of course, scientific theories challenged this view. Copernicus’s heliocentric theory in the 1500s and Darwin’s theory of evolution in the 1800s shook traditional religious worldviews. The revelation that Earth is not the center of the universe, and that humanity is merely one species among countless others, shocked people deeply. Yet humans remained distinctive—we use tools freely, create and use writing systems. The importance of reason, as Aristotle claimed, remained valid. Even as science and technology refuted parts of anthropocentric thinking, they became tools that accelerated civilization and elevated humanity’s status. New interpretations of anthropocentrism prevented science and technology from diminishing human worth.</p> <h2 id="the-rise-of-computing-and-ai">The Rise of Computing and AI</h2> <blockquote> <p>“I believe that in about fifty years’ time it will be possible to programme computers, with a storage capacity of about $10^9$, to make them play the imitation game so well that an average interrogator will not have more than 70 percent chance of making the right identification after five minutes of questioning. … I believe that at the end of the century the use of words and general educated opinion will have altered so much that one will be able to speak of machines thinking without expecting to be contradicted.”</p> <p>— A. M. TURING, I.—COMPUTING MACHINERY AND INTELLIGENCE, <em>Mind</em>, Volume LIX, Issue 236, October 1950, Pages 433–460</p> </blockquote> <p>Today’s computers are physical implementations of the logical structures underlying rational thought, abstracted into computable forms. However, mere computational ability does not imply intelligence, and it actually took a long time before human intelligence could be meaningfully simulated by computers. In 1950, Turing predicted in his paper “Computing Machinery and Intelligence” that machines capable of “not exceeding 70 percent probability of correct identification between machine and human after five minutes of questioning” would appear around 2000, fifty years later. While it’s remarkable that the founder of computers early predicted AI development and devised a test (the Turing Test) to evaluate it, “Moravec’s paradox”—where tasks easy for one system are difficult for another operating on entirely different physical foundations—persisted for a long time.</p> <p>Thanks to Moravec’s paradox, among various domains of intelligence, “learning” seemed to remain a uniquely human domain. However, due to rapid developments in machine learning, AI has developed enough to replace much of human intellectual labor. We are recently witnessing cases across all fields where AI produces superior intellectual outputs compared to experts in each field. OpenAI’s recently released GPT-5 Pro model, capable of various tool use, shows 89.4% accuracy on GPQA Diamond. This benchmark is designed to evaluate graduate-level knowledge and reasoning - and yet, most frontier language models surpasses the 81.3% accuracy of PhD-level expert groups in each field. It shows 42.0% accuracy on the “Humanity’s Last Exam” benchmark - a benchmark with questions drawn from expert-level knowledge across numerous disciplines, including advanced mathematics, physics, biology, and specialized fields like ancient Roman inscriptions or avian anatomy. Setting aside perceptual changes needed for the society to accept AI and solely judging from the indicators, many white-collar jobs including civil servants, developers, and consultants appear likely to become automatable by machines fairly soon. Like machines during the Luddite movement, AI in modern society approaches many as an existential threat.</p> <h2 id="the-irony-of-automation">The Irony of Automation</h2> <p>Now it seems all that remains for us is correcting mistakes when these machines cause errors. In his paper “Ironies of Automation,” Lisanne Bainbridge argued that in an automated society, humans only play roles of monitoring and intervening when automation fails, but since such roles occur very rarely, humans fail to acquire the skills and experience needed when they must actually intervene. Kant’s ought-implies-can principle assumes that to fulfill an obligation, one must necessarily possess the ability to perform that obligation. Accordingly, for an actor to bear moral responsibility, free will must come first. Although ways automation fails vary, the fact that humans must ultimately bear responsibility for all these situations seems clear within current legal frameworks. Can humans bear full responsibility for actions of current AI “agents” not considered to possess free will?</p> <h2 id="science-objectivity-and-value-judgments">Science, Objectivity, and Value Judgments</h2> <p>Of course, one could argue for or against holding AI responsible by quantifying concepts like consciousness and free will, then creating a metric for how capable a system is to take responsibility. For instance, introducing Integrated Information Theory to calculate the strength of consciousness, or adopting theories like Orchestrated Objective Reduction to clarify free will. Such acts of developing quantified scales to analyze problem situations or defining physical quantities for mathematical analysis are all routine procedures for scientists.</p> <p>According to classical positivism, as articulated by Auguste Comte, science exists “to explain objectively observable phenomena more clearly and rigorously through logical structures.” Logical positivism went further: only propositions provable through pure logic and mathematics, or grounded in observable facts, were believed to have cognitive meaning. During the 19th and 20th centuries, positivism was such a dominant ideology in science that anything not objective or observable was simply excluded.</p> <p>Of course, positivism is now over two hundred years old, and among contemporary philosophers of science, scientific realism enjoys majority support. Yet even scientific realism maintains that scientific objects exist independently of mind. Either way, the fences we’ve erected to approach truth form barriers that prevent individual value judgments from influencing science. When approaching problems of intelligence, self-awareness, free will, and social responsibility, we face considerable barriers that science alone cannot overcome. In short, science loses much of its power the moment value judgments become necessary.</p> <h2 id="the-need-for-humanities-in-ai-research">The Need for Humanities in AI Research</h2> <p>In AI academia today, as in other scientific and engineering fields, mathematical analysis and experimental evidence are essentially required for publication in major conferences. This makes sense—after all, why else would we borrow rigorous concepts like vectors, parameters, and datasets except to ground our thinking technically? Yet to accurately describe mental states, we need more than scientifically rigorous objects. We also need humanities concepts centered on subjective experience and value judgment. Whether purely scientific approaches can fully explain intelligent subjects like humans and AI remains an open question. Moreover, no matter how objectively researchers try to proceed, we must acknowledge that researchers themselves are human, and their theoretical assumptions and biases inevitably shape what they observe.</p> <p>Post-positivism, which critiques and revises positivism, recognizes researchers’ biases as problems to be solved in approaching absolute truth. Researchers must constantly work to recognize and correct their biases. But are these biases and values necessarily problematic? We’ve been obsessed with objectivity for so long. What if relaxing that obsession could help us propose new concepts and expand research horizons?</p> <p><img src="/assets/img/blog/ai-humanities/chatgpt-review.png" alt="Example of AI interaction"/></p> <p>Consider, for example, a researcher exploring how AI robots interact with society and how the public comes to accept them. Today’s society doesn’t require us to treat ChatGPT with moral consideration. But in a future where robots become truly indistinguishable from humans in both behavior and appearance, won’t some people argue that robots deserve to be treated as equals? The ChatGPT App Store review shown above reveals something important: regardless of one’s philosophical stance, the general public is already being persuaded by AI, finding comfort in it, and forming emotional connections. When designing “non-humans” who will share our daily lives, can engineering approaches focused solely on optimizing benchmark scores adequately capture the complex and historically unprecedented interactions between humans and machines?</p> <h2 id="similarity-empathy-and-legal-frameworks">Similarity, Empathy, and Legal Frameworks</h2> <p>We must now place individual subjectivity and value judgments at the center of AI research. Consider a child who grows attached to a nearly human-seeming AI housekeeping robot. There are no “objective” grounds for claiming that disposing of the robot would be unethical. Yet from the child’s subjective perspective, stuffed animals, puppies, and helpful robots all seem similar enough to warrant protection. The belief that others are my equals rests fundamentally on “mutual similarity.” If we didn’t believe others were equal despite their similarity to us, and if harm to others didn’t threaten us, there would be no reason to sanction wrongs done to them. But mutual similarity makes harm to others feel like a threat to ourselves, and thus leads us to recognize them as equals.</p> <p>Law protects people from wrongs committed by other people; it doesn’t protect machines. Most AI scholars don’t believe machines have minds, and many share Noam Chomsky’s view that LLMs are merely “statistical parrots.” From a physical standpoint, humans and machines differ fundamentally—in materials, in mechanisms. Yet similarity is judged subjectively, and perception shifts with subjectivity. Appealing to physical differences alone cannot explain the complex social phenomenon captured in the screenshot above.</p> <h2 id="conclusion-designing-a-harmonious-future">Conclusion: Designing a Harmonious Future</h2> <p>As we’ve seen, AI has moved beyond simple computation into learning, reasoning, and creativity, forcing us to reexamine what we thought were uniquely human characteristics—reason, consciousness, responsibility, social bonds. While positivism and logical positivism focused on objective facts and pure logic, post-positivism questions even researchers’ subjectivity and value judgments. But science is only a tool. We must now ask: what questions should we pursue? What kind of society do we want to build? This represents a necessary paradigm shift for AI research. Understanding AI in context—what it means, how far our responsibility extends—has become paramount.</p> <p>In future societies where AI agents take on extensive roles—in production, services, caregiving, and creative work—the old assumption that “machines are just machines” will no longer hold. We may need new frameworks based on concepts like mutual similarity and emotional bonds. Designing legal and ethical systems that address attachment to robots and justify their protection will require fundamentally expanding the notion of legal personhood beyond humans. We must specify who bears responsibility when care robots make errors, and consider whether AI itself might someday hold certain rights and duties.</p> <p>Ultimately, AI-era researchers and policymakers must think as deeply about what makes us human as they do about technical performance. Science explores objective truth, but we must simultaneously work to understand subjective experience and social context. Humanities, social sciences, and law must join engineering in the laboratory and at the policy table. Only then can we design a society where humans and AI coexist while preserving human dignity and responsibility.</p>]]></content><author><name></name></author><category term="essay"/><category term="artificial-intelligence"/><category term="philosophy"/><category term="humanities"/><category term="ethics"/><category term="consciousness"/><category term="responsibility"/><category term="english"/><summary type="html"><![CDATA[Exploring the essential role of humanities in AI research]]></summary></entry><entry><title type="html">TEST 01 : 정답</title><link href="https://codingjang.github.io/blog/2024/tutoring-test-similarity-answer/" rel="alternate" type="text/html" title="TEST 01 : 정답"/><published>2024-07-02T01:00:00+00:00</published><updated>2024-07-02T01:00:00+00:00</updated><id>https://codingjang.github.io/blog/2024/tutoring-test-similarity-answer</id><content type="html" xml:base="https://codingjang.github.io/blog/2024/tutoring-test-similarity-answer/"><![CDATA[<p><em>본 자료는 인공지능을 활용하지 않고 작성되었음을 알립니다.</em></p> <p><a href="/blog/2021/tutoring-test-similarity/">문제로 돌아가기</a></p> <p><strong>문제 1 정답:</strong> $\frac{3}{2}\rm{cm}$</p> <p><img src="/assets/img/blog/tutoring/Untitled.png" alt="Untitled"/></p> <p><strong>문제 2 정답:</strong> $\frac{168}{125} \rm{cm}$</p> <p><img src="/assets/img/blog/tutoring/Untitled%201.png" alt="Untitled"/></p> <p><strong>문제 3 정답:</strong> $9:4$</p> <p><img src="/assets/img/blog/tutoring/Untitled%202.png" alt="Untitled"/></p> <p><strong>문제 4 정답:</strong> $\frac{27}{2}\rm{cm}$</p> <p><img src="/assets/img/blog/tutoring/Untitled%203.png" alt="Untitled"/></p> <p><strong>문제 5 정답:</strong> $b^2=ac$</p> <p><img src="/assets/img/blog/tutoring/Untitled%204.png" alt="Untitled"/></p>]]></content><author><name></name></author><category term="education"/><category term="education"/><category term="tutoring"/><category term="mathematics"/><category term="korean"/><summary type="html"><![CDATA[수학 교육 자료]]></summary></entry></feed>